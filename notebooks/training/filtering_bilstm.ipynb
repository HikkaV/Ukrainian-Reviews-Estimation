{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0193b1ab-8909-4341-9fa8-eeed7486285f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers\n",
      "  Downloading tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers\n",
      "Successfully installed tokenizers-0.13.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 09:50:34.342919: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers\n",
    "import tensorflow as tf\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, trainers, Regex\n",
    "import tokenizers\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1179f8f4-b348-43a1-b21b-ec6b44e5eaef",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5032649e-505b-4adb-b155-c76d1f468261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/user/files_for_research_Vova/processed_data.csv', usecols=['review_translate',\n",
    "                                                            'dataset_name',\n",
    "                                                            'rating',\n",
    "                                                           'translated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f961129a-3271-4e47-ac97-34c69e79574a",
   "metadata": {},
   "source": [
    "# Load tokenizer and encode text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0496b85-4884-4d03-8a7b-b944b6e8958c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_file(\"/home/user/files_for_research_Vova/tokenizer_30k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dac6f83-d35a-49f6-9412-7e98817adf2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['review_translate'] = df['review_translate'].str.lower()\n",
    "df['encoded'] = tokenizer.encode_batch(df['review_translate'].values)\n",
    "df['encoded'] = df['encoded'].apply(lambda x: x.ids)\n",
    "encoded_tokens = df['encoded'].values\n",
    "padded_tokens = tf.keras.preprocessing.sequence\\\n",
    ".pad_sequences(encoded_tokens, maxlen=300, padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa58f226-c41c-411f-9154-2bd25303fafc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping = dict([(i,c) for c,i in enumerate(df['rating'].unique())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e131b204-3736-4278-9bca-fe40d67500e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = df['rating'].map(mapping).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44beb99-8a3c-400e-a180-79193f0bcdd5",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cee498b5-c5ef-4d00-a6b9-f2b7863cea42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(pool_window = 2,\n",
    "output_dim = 300, \n",
    "                num_classes=5):\n",
    "    tf.keras.backend.clear_session()\n",
    "    np.random.seed(0)\n",
    "    tf.random.set_seed(0)\n",
    "    input_layer = tf.keras.layers.Input(shape=(300,), name='input')\n",
    "    word_embedding = tf.keras.layers.Embedding(input_dim=tokenizer.get_vocab_size(),\n",
    "                                                       output_dim=300,\n",
    "                                                       trainable=True,\n",
    "                                               name='embedding',\n",
    "                                               mask_zero=True\n",
    "                                                       )\n",
    "    dropout = tf.keras.layers.SpatialDropout1D(0.3)\n",
    "    lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, name='lstm'))\n",
    "    embedded = dropout(word_embedding(input_layer))\n",
    "    hidden = lstm(embedded)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', name='dense')(hidden)\n",
    "    x = tf.keras.layers.Dropout(0.5, name='dropout')(x)\n",
    "    output = tf.keras.layers.Dense(num_classes, activation='softmax', name='output')(x)\n",
    "    model = tf.keras.Model(input_layer, output)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', \\\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "             metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf84cf8-c334-4f61-8fbb-1d3a63491af5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2265ed3a-0424-46cd-97e5-102a60df9a43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "class EarlyStopping:\n",
    "    def __init__(self, tolerance=5, mode='min'):\n",
    "        assert mode in ['min','max'], 'Mode should be min or max'\n",
    "        self.mode = operator.lt if mode=='min' else operator.gt \n",
    "        self.tolerance = tolerance\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.extremum_value = None\n",
    "        self.best_model = None\n",
    "    \n",
    "    @staticmethod\n",
    "    def copy_model(model):\n",
    "        copied_model = tf.keras.models.clone_model(model)\n",
    "        copied_model.set_weights(model.get_weights())\n",
    "        return copied_model\n",
    "        \n",
    "    def __call__(self, val, model):\n",
    "        if self.extremum_value is None:\n",
    "            self.extremum_value = val\n",
    "            self.best_model = self.copy_model(model)\n",
    "        else:\n",
    "            if not self.mode(val, self.extremum_value):\n",
    "                self.counter+=1\n",
    "            else:\n",
    "                self.extremum_value = val\n",
    "                self.best_model = self.copy_model(model)\n",
    "                self.counter = 0\n",
    "        \n",
    "        if self.counter==self.tolerance:\n",
    "            self.early_stop=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e991435f-1d54-4417-b17b-28046f22c479",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e24892ff-3fe1-4a72-9aed-4f11dfada769",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d723c473-9913-48cc-b360-ea99a96e65d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filtering(X, y, ids, path, n_splits=5, epochs=10, batch_size=2024):\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=n_splits)\n",
    "    early_stopping = EarlyStopping(4, 'max')\n",
    "    f1_scores = []\n",
    "    \n",
    "    c = 1\n",
    "    start_time = time.time()\n",
    "    for train_idx, val_idx in kfold.split(range(len(X)), y):\n",
    "         # data split\n",
    "        X_train = X[train_idx]\n",
    "        X_val = X[val_idx]\n",
    "        \n",
    "        y_train = y[train_idx]\n",
    "        y_val = y[val_idx]\n",
    "        \n",
    "        val_ids = ids[val_idx]\n",
    "        \n",
    "        #create model\n",
    "        model = create_model(num_classes=5)\n",
    "        \n",
    "        #train model\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            history = model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "              epochs=1, batch_size=batch_size,\n",
    "                               verbose=0)\n",
    "        \n",
    "            #evaluate model\n",
    "            val_prediction = np.argmax(model.predict(X_val), axis=-1)\n",
    "            val_f1 = f1_score(y_true=y_val, y_pred=val_prediction,\n",
    "                         average='micro')\n",
    "            \n",
    "            f1_scores.append(val_f1)\n",
    "        \n",
    "            #early stopping\n",
    "            early_stopping(val_f1, model)\n",
    "            if early_stopping.early_stop:\n",
    "                model = early_stopping.best_model\n",
    "                break\n",
    "                \n",
    "        #save predictions\n",
    "        predicted_y_val = model.predict(X_val)\n",
    "        df = pd.DataFrame()\n",
    "        df['id'] = val_ids\n",
    "        df['y_predicted_proba'] = predicted_y_val.tolist()\n",
    "        df['y_true'] = y_val\n",
    "        df.to_csv(path, mode='a', index=False)\n",
    "\n",
    "        print(f'Done with {c} fold') \n",
    "        c+=1 \n",
    "        \n",
    "        del model, df, predicted_y_val;\n",
    "        gc.collect();\n",
    "        \n",
    "    end_time = time.time()\n",
    "    print(f'It took : {(end_time-start_time)/60} minutes')\n",
    "    \n",
    "    return f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "690ebad6-9132-4a1a-9116-38a29e3a2f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids = np.array(list(range(len(padded_tokens))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5943725d-59e4-4bfd-be66-860386165aec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "908e72ca-571c-4c30-b704-a27dc6109c98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 09:51:40.090095: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-18 09:51:40.249536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1621] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14148 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:03:00.0, compute capability: 8.6\n",
      "2023-04-18 09:51:51.366682: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'cond_40/output/_23'\n",
      "2023-04-18 09:51:51.810916: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8700\n",
      "2023-04-18 09:51:52.153449: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:648] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-04-18 09:51:52.212759: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f94f097fc40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-18 09:51:52.212846: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA RTX A4000, Compute Capability 8.6\n",
      "2023-04-18 09:51:52.220899: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-18 09:51:52.393028: I tensorflow/compiler/jit/xla_compilation_cache.cc:480] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 60s 14ms/step\n",
      "4144/4144 [==============================] - 56s 14ms/step\n",
      "4144/4144 [==============================] - 57s 14ms/step\n",
      "4144/4144 [==============================] - 56s 14ms/step\n",
      "4144/4144 [==============================] - 56s 14ms/step\n",
      "4144/4144 [==============================] - 57s 14ms/step\n",
      "4144/4144 [==============================] - 57s 13ms/step\n",
      "Done with 1 fold\n",
      "4144/4144 [==============================] - 62s 14ms/step\n",
      "4144/4144 [==============================] - 58s 14ms/step\n",
      "Done with 2 fold\n",
      "4144/4144 [==============================] - 65s 15ms/step\n",
      "4144/4144 [==============================] - 60s 14ms/step\n",
      "Done with 3 fold\n",
      "4144/4144 [==============================] - 73s 17ms/step\n",
      "4144/4144 [==============================] - 70s 17ms/step\n",
      "Done with 4 fold\n",
      "4144/4144 [==============================] - 70s 16ms/step\n",
      "4144/4144 [==============================] - 67s 16ms/step\n",
      "Done with 5 fold\n",
      "It took : 28.653895366191865 minutes\n"
     ]
    }
   ],
   "source": [
    "f1_scores = filtering(padded_tokens, y, ids,\\\n",
    "                      '/home/user/files_for_research_Vova/filtering_bilstm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55a527ab-634a-43a3-8b86-b37a0e9a9489",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7072000724080192,\n",
       " 0.7109411533994056,\n",
       " 0.7096287580516208,\n",
       " 0.7015658234149432,\n",
       " 0.7042434116245041,\n",
       " 0.7000648655171894,\n",
       " 0.70768279253594,\n",
       " 0.707273289536208,\n",
       " 0.5592656564666129,\n",
       " 0.7339965756782646]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd20bf54-939e-429d-9fa8-9159f71f8ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cuda12",
   "language": "python",
   "name": "tensorflow_cuda12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
