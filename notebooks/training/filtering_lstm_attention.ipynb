{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0193b1ab-8909-4341-9fa8-eeed7486285f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers\n",
      "  Downloading tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers\n",
      "Successfully installed tokenizers-0.13.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 08:27:19.547674: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers\n",
    "import tensorflow as tf\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, trainers, Regex\n",
    "import tokenizers\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1179f8f4-b348-43a1-b21b-ec6b44e5eaef",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5032649e-505b-4adb-b155-c76d1f468261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/user/files_for_research_Vova/processed_data.csv', usecols=['review_translate',\n",
    "                                                            'dataset_name',\n",
    "                                                            'rating',\n",
    "                                                           'translated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f961129a-3271-4e47-ac97-34c69e79574a",
   "metadata": {},
   "source": [
    "# Load tokenizer and encode text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0496b85-4884-4d03-8a7b-b944b6e8958c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_file(\"/home/user/files_for_research_Vova/tokenizer_30k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dac6f83-d35a-49f6-9412-7e98817adf2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['review_translate'] = df['review_translate'].str.lower()\n",
    "df['encoded'] = tokenizer.encode_batch(df['review_translate'].values)\n",
    "df['encoded'] = df['encoded'].apply(lambda x: x.ids)\n",
    "encoded_tokens = df['encoded'].values\n",
    "padded_tokens = tf.keras.preprocessing.sequence\\\n",
    ".pad_sequences(encoded_tokens, maxlen=300, padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa58f226-c41c-411f-9154-2bd25303fafc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping = dict([(i,c) for c,i in enumerate(df['rating'].unique())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e131b204-3736-4278-9bca-fe40d67500e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = df['rating'].map(mapping).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44beb99-8a3c-400e-a180-79193f0bcdd5",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cabbf294-4d26-4ba1-90bd-c2aba5653b47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self,  \n",
    "                 units=128, **kwargs):\n",
    "        super(Attention,self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.W1=self.add_weight(name='attention_weights_1', shape=(input_shape[-1], self.units), \n",
    "                               initializer='glorot_uniform', trainable=True)\n",
    "        \n",
    "        self.W2=self.add_weight(name='attention_weights_2', shape=(1, self.units), \n",
    "                               initializer='glorot_uniform', trainable=True) \n",
    "        \n",
    "        super(Attention, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = tf.transpose(x, perm=[0, 2, 1])\n",
    "        attention = tf.nn.softmax(tf.matmul(self.W2, tf.nn.tanh(tf.matmul(self.W1, x))))\n",
    "        weighted_context = tf.reduce_sum(x * attention, axis=-1)\n",
    "        return weighted_context, attention\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'units': self.units\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cee498b5-c5ef-4d00-a6b9-f2b7863cea42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(pool_window = 2,\n",
    "output_dim = 300, \n",
    "                num_classes=5):\n",
    "    tf.keras.backend.clear_session()\n",
    "    np.random.seed(0)\n",
    "    tf.random.set_seed(0)\n",
    "    # define layers\n",
    "    attention = Attention(units=128, name='attention')\n",
    "    input_layer = tf.keras.layers.Input(shape=(300,), name='input')\n",
    "    word_embedding = tf.keras.layers.Embedding(input_dim=tokenizer.get_vocab_size(),\n",
    "                                                       output_dim=300,\n",
    "                                                       trainable=True,\n",
    "                                               name='embedding',\n",
    "                                               mask_zero=True\n",
    "                                                       )\n",
    "    spatial_dropout = tf.keras.layers.SpatialDropout1D(0.3, name='spatial_dropout')\n",
    "    lstm = tf.keras.layers.LSTM(128, name='lstm',\n",
    "                                return_sequences=True, return_state=True)\n",
    "    dense1 = tf.keras.layers.Dense(128, activation='relu', name='dense')\n",
    "    dropout = tf.keras.layers.Dropout(0.5, name='dropout')\n",
    "    logits_layer = tf.keras.layers.Dense(num_classes, activation='softmax', name='output')\n",
    "\n",
    "    #actual flow\n",
    "    embedded = spatial_dropout(word_embedding(input_layer))\n",
    "    context_vector, state_h, _ = lstm(embedded)\n",
    "    weighted_context, attention_scores = attention(context_vector)\n",
    "    final_attn_output = tf.concat([state_h, weighted_context], axis=1)\n",
    "    x = dense1(final_attn_output)\n",
    "    x = dropout(x)\n",
    "    x = logits_layer(x)\n",
    "    model = tf.keras.Model(input_layer, x)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', \\\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "             metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf84cf8-c334-4f61-8fbb-1d3a63491af5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2265ed3a-0424-46cd-97e5-102a60df9a43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "class EarlyStopping:\n",
    "    def __init__(self, tolerance=5, mode='min'):\n",
    "        assert mode in ['min','max'], 'Mode should be min or max'\n",
    "        self.mode = operator.lt if mode=='min' else operator.gt \n",
    "        self.tolerance = tolerance\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.extremum_value = None\n",
    "        self.best_model = None\n",
    "    \n",
    "    @staticmethod\n",
    "    def copy_model(model):\n",
    "        copied_model = tf.keras.models.clone_model(model)\n",
    "        copied_model.set_weights(model.get_weights())\n",
    "        return copied_model\n",
    "        \n",
    "    def __call__(self, val, model):\n",
    "        if self.extremum_value is None:\n",
    "            self.extremum_value = val\n",
    "            self.best_model = self.copy_model(model)\n",
    "        else:\n",
    "            if not self.mode(val, self.extremum_value):\n",
    "                self.counter+=1\n",
    "            else:\n",
    "                self.extremum_value = val\n",
    "                self.best_model = self.copy_model(model)\n",
    "                self.counter = 0\n",
    "        \n",
    "        if self.counter==self.tolerance:\n",
    "            self.early_stop=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e991435f-1d54-4417-b17b-28046f22c479",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e24892ff-3fe1-4a72-9aed-4f11dfada769",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d723c473-9913-48cc-b360-ea99a96e65d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filtering(X, y, ids, path, n_splits=5, epochs=10, batch_size=2024):\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=n_splits)\n",
    "    early_stopping = EarlyStopping(4, 'max')\n",
    "    f1_scores = []\n",
    "    \n",
    "    c = 1\n",
    "    start_time = time.time()\n",
    "    for train_idx, val_idx in kfold.split(range(len(X)), y):\n",
    "         # data split\n",
    "        X_train = X[train_idx]\n",
    "        X_val = X[val_idx]\n",
    "        \n",
    "        y_train = y[train_idx]\n",
    "        y_val = y[val_idx]\n",
    "        \n",
    "        val_ids = ids[val_idx]\n",
    "        \n",
    "        #create model\n",
    "        model = create_model(num_classes=5)\n",
    "        \n",
    "        #train model\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            history = model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "              epochs=1, batch_size=batch_size,\n",
    "                               verbose=0)\n",
    "        \n",
    "            #evaluate model\n",
    "            val_prediction = np.argmax(model.predict(X_val), axis=-1)\n",
    "            val_f1 = f1_score(y_true=y_val, y_pred=val_prediction,\n",
    "                         average='micro')\n",
    "            \n",
    "            f1_scores.append(val_f1)\n",
    "        \n",
    "            #early stopping\n",
    "            early_stopping(val_f1, model)\n",
    "            if early_stopping.early_stop:\n",
    "                model = early_stopping.best_model\n",
    "                break\n",
    "                \n",
    "        #save predictions\n",
    "        predicted_y_val = model.predict(X_val)\n",
    "        df = pd.DataFrame()\n",
    "        df['id'] = val_ids\n",
    "        df['y_predicted_proba'] = predicted_y_val.tolist()\n",
    "        df['y_true'] = y_val\n",
    "        df.to_csv(path, mode='a', index=False)\n",
    "\n",
    "        print(f'Done with {c} fold') \n",
    "        c+=1 \n",
    "        \n",
    "        del model, df, predicted_y_val;\n",
    "        gc.collect();\n",
    "        \n",
    "    end_time = time.time()\n",
    "    print(f'It took : {(end_time-start_time)/60} minutes')\n",
    "    \n",
    "    return f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "690ebad6-9132-4a1a-9116-38a29e3a2f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids = np.array(list(range(len(padded_tokens))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5943725d-59e4-4bfd-be66-860386165aec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "908e72ca-571c-4c30-b704-a27dc6109c98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 08:34:54.346775: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8700\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14835253248 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-04-18 08:34:55.116053: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8700\n",
      "2023-04-18 08:34:55.225997: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:648] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-04-18 08:34:55.264892: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fcbf0970130 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-18 08:34:55.264957: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA RTX A4000, Compute Capability 8.6\n",
      "2023-04-18 08:34:55.273237: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-18 08:34:55.445250: I tensorflow/compiler/jit/xla_compilation_cache.cc:480] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-04-18 08:36:16.567599: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8700\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14835253248 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-04-18 08:36:20.862707: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8700\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14835253248 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 51s 12ms/step\n",
      "4144/4144 [==============================] - 50s 12ms/step\n",
      "4144/4144 [==============================] - 51s 12ms/step\n",
      "4144/4144 [==============================] - 49s 12ms/step\n",
      "4144/4144 [==============================] - 51s 12ms/step\n",
      "4144/4144 [==============================] - 50s 12ms/step\n",
      "4144/4144 [==============================] - 50s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 08:45:47.502862: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8700\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14835253248 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 51s 12ms/step\n",
      "Done with 1 fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 08:46:47.499461: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8700\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14835253248 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-04-18 08:48:03.094605: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8700\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14835253248 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-04-18 08:48:07.410308: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8700\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14835253248 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 51s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 08:49:01.436395: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8700\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14835253248 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 50s 12ms/step\n",
      "Done with 2 fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 08:50:02.929149: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8700\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14835253248 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-04-18 08:51:21.811745: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8700\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14835253248 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-04-18 08:51:26.186547: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8700\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14835253248 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 54s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 08:52:22.188484: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8700\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14835253248 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 51s 12ms/step\n",
      "Done with 3 fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 08:53:24.503695: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8700\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14835253248 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-04-18 08:54:48.325785: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8700\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14835253248 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-04-18 08:54:52.623933: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8700\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14835253248 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 58s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 08:55:53.748878: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8700\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14835253248 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 57s 14ms/step\n",
      "Done with 4 fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 08:57:01.954648: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8700\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14835253248 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-04-18 08:58:19.335794: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8700\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14835253248 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-04-18 08:58:23.776838: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8700\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14835253248 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 60s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 08:59:28.515648: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA RTX A4000\" frequency: 1560 num_cores: 48 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12000\" } environment { key: \"cudnn\" value: \"8700\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 102400 memory_size: 14835253248 bandwidth: 448064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 56s 13ms/step\n",
      "Done with 5 fold\n",
      "It took : 25.678119452794395 minutes\n"
     ]
    }
   ],
   "source": [
    "f1_scores = filtering(padded_tokens, y, ids,\\\n",
    "                      '/home/user/files_for_research_Vova/filtering_lstm_attention.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55a527ab-634a-43a3-8b86-b37a0e9a9489",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7041378165965214,\n",
       " 0.7087085728077719,\n",
       " 0.7090630704017136,\n",
       " 0.7070039673560513,\n",
       " 0.7084747552458103,\n",
       " 0.6968894721757102,\n",
       " 0.6928768611123682,\n",
       " 0.704786471768415,\n",
       " 0.7063606399106961,\n",
       " 0.5995353783724666,\n",
       " 0.7300216471440101]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd20bf54-939e-429d-9fa8-9159f71f8ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cuda12",
   "language": "python",
   "name": "tensorflow_cuda12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
