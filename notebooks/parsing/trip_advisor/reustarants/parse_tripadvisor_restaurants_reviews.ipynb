{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "177e3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import ElementClickInterceptedException, StaleElementReferenceException\n",
    "import os\n",
    "from random_user_agent.user_agent import UserAgent\n",
    "from random_user_agent.params import SoftwareName, OperatingSystem\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import json\n",
    "import pickle\n",
    "import urllib\n",
    "from functools import partial\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from random_user_agent.user_agent import UserAgent\n",
    "from random_user_agent.params import OperatingSystem, SoftwareName\n",
    "import pyautogui\n",
    "import threading\n",
    "import multiprocessing\n",
    "from selenium.webdriver.common.proxy import Proxy, ProxyType\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35caa5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_link(link, num):\n",
    "    before_link, after_link = link.split('Reviews')\n",
    "    return before_link+'Reviews-'+f'or{num*10}'+after_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f5696b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f09d43c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import Pool\n",
    "from contextlib import closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24f7b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiprocess_func(main_input, func, additional_inputs=None,\n",
    "                      gather_func=None, to_split=True, gather_func_args=None,\n",
    "                      chunk_size=100, n_processes=8):\n",
    "    if not gather_func_args:\n",
    "        gather_func_args = []\n",
    "    if not additional_inputs:\n",
    "        additional_inputs = []\n",
    "    if not gather_func:\n",
    "        gather_func = lambda x: [z for i in x for z in i]\n",
    "    if to_split:\n",
    "        splitted = [(main_input[i:i + chunk_size], *additional_inputs) if additional_inputs else main_input[i:i + chunk_size]\\\n",
    "                    for i in range(0, len(main_input), chunk_size)]\n",
    "    else:\n",
    "        splitted = [(i, *additional_inputs) if additional_inputs else i for i in main_input]\n",
    "    with closing(Pool(n_processes)) as p:\n",
    "        result = list(tqdm(p.imap(func, splitted),\n",
    "                           total=len(splitted)))\n",
    "    return gather_func(result, *gather_func_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1236cfb",
   "metadata": {},
   "source": [
    "# Second level parsing with translate + selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c846bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_df = pd.read_csv('links_to_restaurants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b5b4973",
   "metadata": {},
   "outputs": [],
   "source": [
    "software_names = [SoftwareName.CHROME.value]\n",
    "operating_systems = [OperatingSystem.LINUX, OperatingSystem.MACOS.value,\n",
    "                    OperatingSystem.WINDOWS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f9cd1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent_rotator = UserAgent(software_names=software_names,\n",
    "                               operating_systems=operating_systems, limit=links_df.shape[0]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b571213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_html(file, path):\n",
    "    with open(path+'.html', 'w') as f:\n",
    "        f.write(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b33cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_driver(user_agent, run_headless=False):\n",
    "    custom_options = webdriver.ChromeOptions()\n",
    "    prox = \"socks5://localhost:9050\"\n",
    "    custom_options.add_argument('--proxy-server=%s' % prox)\n",
    "    \n",
    "    if run_headless:\n",
    "        custom_options.add_argument('headless')\n",
    "    custom_options.add_argument(\"lang=uk\")\n",
    "    custom_options.add_argument('--ignore-certificate-errors')\n",
    "    custom_options.add_argument('--disable-dev-shm-usage')\n",
    "    custom_options.add_argument(f'user-agent={user_agent}')\n",
    "    driver = webdriver.Chrome(options=custom_options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f749f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ip_proxy(address):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    options.add_argument('headless')\n",
    "\n",
    "    prox = \"socks5://localhost:9050\"\n",
    "    options.add_argument('--proxy-server=%s' % prox)\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get('https://api.ipify.org/')\n",
    "    ip_address = driver.find_element(By.TAG_NAME, \"body\").text\n",
    "    driver.quit()\n",
    "    \n",
    "    return ip_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a93619be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_change_ip(address, default_ip_address, debug=False):\n",
    "    try:\n",
    "        ip_address = check_ip_proxy(address)\n",
    "    except:\n",
    "        ip_address = None\n",
    "    \n",
    "    if debug:\n",
    "        print(f'Old ip: {default_ip_address}, new ip : {ip_address}')\n",
    "        \n",
    "    if default_ip_address!=ip_address and ip_address:\n",
    "        if debug:\n",
    "            print('IPs are different')\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bd68acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def access_denied_check_with_address(address, url):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    options.add_argument('headless')\n",
    "    prox = \"socks5://localhost:9050\"\n",
    "    options.add_argument('--proxy-server=%s' % prox)\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "    except:\n",
    "        driver.quit()\n",
    "        return False\n",
    "    \n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    try:\n",
    "        return bs4.BeautifulSoup(html).find('head').title.text!='Access Denied'\n",
    "    except:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0acde8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def access_denied_check_with_page(html):\n",
    "    try:\n",
    "        return bs4.BeautifulSoup(html).find('head').title.text!='Access Denied'\n",
    "    except:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ed3f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_free_proxies():\n",
    "    ips = []\n",
    "    url = 'https://free-proxy-list.net/'\n",
    "    soup = bs4.BeautifulSoup(requests.get(url).text)\n",
    "    for i in soup.find('table', {'class':'table table-striped table-bordered'}).find_all('tr'):\n",
    "        found = i.find_all('td')[:2]\n",
    "        if found:\n",
    "            ip, port = found\n",
    "            ips.append(ip.text+':'+port.text)\n",
    "    return ips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2b1abcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_and_click_by(driver, value, by, time_sleep=15):\n",
    "    WebDriverWait(driver, time_sleep).until(EC.presence_of_element_located((by, value)))\n",
    "    driver.find_element(by=by, value=value).click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0f014d",
   "metadata": {},
   "source": [
    "## chek proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e6684ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from stem import Signal\n",
    "from stem.control import Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5abca62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_ip():\n",
    "    with Controller.from_port(port = 9051) as controller:\n",
    "        controller.authenticate() \n",
    "        controller.signal(Signal.NEWNYM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e362670",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_ip = check_ip_proxy('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c002bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'51.195.166.195'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_ip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed09ed3",
   "metadata": {},
   "source": [
    "## parsing itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee3e2143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74ce48bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABS_PATH = 'trip_advisor_data_restaurants'\n",
    "if not os.path.exists(ABS_PATH):\n",
    "    os.mkdir(ABS_PATH)\n",
    "    \n",
    "for i in links_df['name_to_save']:\n",
    "    dir_path = os.path.join(ABS_PATH,i)\n",
    "\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2eb84982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_around_block(driver):\n",
    "    try:\n",
    "        WebDriverWait(driver, 2).until(EC.presence_of_element_located((By.CLASS_NAME, 'rebrand_2017')))\n",
    "        driver.find_element(by=By.CLASS_NAME, value='rebrand_2017').click()\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4205a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_reviews(link, path, abs_path, user_agent_rotator,\n",
    "                  parts_scroll=8, sleep_time_list=None, run_headless=True, \n",
    "                 max_errors=3):\n",
    "    \n",
    "    # exception handling \n",
    "    passed = {'got_initial_link': False,\n",
    "              'see_all_languages': False}\n",
    "    passed['link'] = link\n",
    "    passed['hotel_name'] = path\n",
    "    \n",
    "    caught_ex = None\n",
    "        \n",
    "    # overall path\n",
    "    path_to_save = os.path.join(abs_path, path)\n",
    "    \n",
    "    #check if there are already parsed pages\n",
    "    n_already_parsed = len(os.listdir(path_to_save))\n",
    "    if n_already_parsed:\n",
    "        link = augment_link(link, n_already_parsed)    \n",
    "    \n",
    "    # get driver\n",
    "    try:\n",
    "        driver = get_driver(user_agent_rotator.get_random_user_agent(), run_headless)\n",
    "    except Exception as ex:\n",
    "        caught_ex = ex\n",
    "    \n",
    "    if caught_ex:\n",
    "        passed['got_initial_link'] = False\n",
    "        passed['num_overall'] = 9999\n",
    "        passed['num_parsed'] = 0\n",
    "        passed['exception'] = caught_ex\n",
    "        return passed\n",
    "\n",
    "\n",
    "    # initial link getting\n",
    "    try:\n",
    "        driver.get(link)\n",
    "        time.sleep(5)\n",
    "    except Exception as ex:\n",
    "        caught_ex = ex\n",
    "        \n",
    "\n",
    "    if caught_ex:\n",
    "        passed['got_initial_link'] = False\n",
    "        passed['num_overall'] = 9999\n",
    "        passed['num_parsed'] = 0\n",
    "        passed['exception'] = caught_ex\n",
    "        return passed\n",
    "    else:\n",
    "        passed['got_initial_link'] = True\n",
    "\n",
    "    # check if access denied\n",
    "    errors_acccess = 0\n",
    "    while errors_acccess<5:\n",
    "    \n",
    "        if not access_denied_check_with_page(driver.page_source):\n",
    "            caught_ex = 'Access dnied'\n",
    "            change_ip()\n",
    "            driver.execute_cdp_cmd('Network.setUserAgentOverride', {\"userAgent\": user_agent_rotator.get_random_user_agent()})\n",
    "            time.sleep(10)\n",
    "            try:\n",
    "                driver.get(link)\n",
    "            except Exception as ex:\n",
    "                caught_ex = ex\n",
    "                passed['num_overall'] = 9999\n",
    "                passed['num_parsed'] = 0\n",
    "                driver.quit()\n",
    "                return passed\n",
    "            errors_acccess+=1\n",
    "        else:\n",
    "            caught_ex = None\n",
    "            break\n",
    "        \n",
    "    if caught_ex:\n",
    "        passed['got_initial_link'] = False\n",
    "        passed['num_overall'] = 9999\n",
    "        passed['num_parsed'] = 0\n",
    "        passed['exception'] = caught_ex\n",
    "        driver.quit()\n",
    "        return passed\n",
    "    \n",
    "        \n",
    "    # see all languages\n",
    "    try:\n",
    "        wait_and_click_by(driver, 'checkmark', By.CLASS_NAME, 30)\n",
    "        passed['see_all_languages'] = True\n",
    "        time.sleep(5)\n",
    "    except:\n",
    "        passed['see_all_languages'] = False\n",
    "    \n",
    "\n",
    "    c = 0\n",
    "    errors = 0\n",
    "    first_page = None\n",
    "    last_link = None\n",
    "\n",
    "    while True:\n",
    "        passed['show_more'] = False\n",
    "        passed['saved_file'] = False\n",
    "        passed['next_page'] = False\n",
    "\n",
    "\n",
    "        try:\n",
    "            # show more \n",
    "            try:\n",
    "                wait_and_click_by(driver, 'ulBlueLinks', By.CLASS_NAME, 30)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            time.sleep(2)\n",
    "            passed['show_more'] = True\n",
    "            \n",
    "            #get_around_block\n",
    "            get_around_block(driver)\n",
    "            \n",
    "            # if first page, then save it\n",
    "            page_html = driver.page_source\n",
    "\n",
    "            if c == 0:\n",
    "                try:\n",
    "                    passed['num_overall'] = int(bs4.BeautifulSoup(page_html) \\\n",
    "                                                .find('span', {'class': 'reviews_header_count'}).text.replace('(','')\\\n",
    "                                               .replace(')',''))\n",
    "                    passed['got_overall_num'] = True\n",
    "                except:\n",
    "                    passed['got_overall_num'] = False\n",
    "                    passed['num_overall'] = 0\n",
    "                \n",
    "                if 10*n_already_parsed>=passed['num_overall']:\n",
    "                    break\n",
    "                    \n",
    "            \n",
    "            # save to txt\n",
    "            save_html(page_html, os.path.join(path_to_save, f'page_{str(n_already_parsed+c)}'))\n",
    "            time.sleep(1)\n",
    "            passed['saved_file'] = True            \n",
    "            c += 1\n",
    "            \n",
    "            #next button \n",
    "            WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CLASS_NAME, 'ui_button.nav.next')))\n",
    "            button_el = driver.find_element(by=By.CLASS_NAME, value='ui_button.nav.next')\n",
    "            \n",
    "            if button_el.is_enabled() and button_el.is_displayed():\n",
    "                button_el.click()\n",
    "            else:\n",
    "                break\n",
    "            passed['next_page'] = True   \n",
    "            errors = 0\n",
    "            \n",
    "            #breaking if we have same link \n",
    "            if last_link==driver.current_url:\n",
    "                break\n",
    "            \n",
    "            last_link = driver.current_url\n",
    "            \n",
    "        except Exception as ex:\n",
    "            if not isinstance(ex, (StaleElementReferenceException, ElementClickInterceptedException)):\n",
    "                caught_ex = ex\n",
    "                break\n",
    "            else:\n",
    "                errors+=1\n",
    "            if errors>=max_errors:\n",
    "                break  \n",
    "                \n",
    "        finally:\n",
    "            time.sleep(np.random.choice(sleep_time_list))\n",
    "\n",
    "            \n",
    "    driver.quit()\n",
    "    \n",
    "    if not caught_ex:\n",
    "        passed = dict([(k, True) if k in ('next_page', \n",
    "                                         'show_more',\n",
    "                                         'next_page',\n",
    "                                         'saved_file') else (k,v)  for k,v in passed.items()])\n",
    "        \n",
    "\n",
    "    passed['num_parsed'] = 10 * (n_already_parsed+c)\n",
    "    passed['exception'] = caught_ex\n",
    "\n",
    "    return passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffa2330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = links_df[links_df['parsed']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acf772a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170, 7)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b757f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_threads = 8\n",
    "headless = True\n",
    "sleep_time_list = list(range(3,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f69b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_reviews_partial = partial(parse_reviews,\n",
    "                                run_headless=headless,\n",
    "                                sleep_time_list=sleep_time_list,\n",
    "                                user_agent_rotator=user_agent_rotator,\n",
    "                               abs_path=ABS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70c9a9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = links_df[links_df['parsed']==False]\n",
    "input_tuples = list(zip(sub_df['link'].values.tolist(), sub_df['name_to_save'].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49a6e6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "sleep_between_batches_time = [120, 180, 300, 600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "676f3579",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_input_tuples = [input_tuples[i:i+batch_size] for i in range(0, len(input_tuples)+batch_size, batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3bd9c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_reviews_multiprocessing(input_tuple):\n",
    "    link, path= input_tuple\n",
    "    passed_dict = parse_reviews_partial(link, path=path)\n",
    "    return passed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f4d21f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 100/100 [24:08<00:00, 14.49s/it]\n",
      "100%|████████████████████████████████████████| 70/70 [19:45<00:00, 16.94s/it]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "passed = []\n",
    "for batch in batched_input_tuples[:20]:\n",
    "    with closing(ThreadPool(n_threads)) as p:\n",
    "        results = list(tqdm(p.imap(parse_reviews_multiprocessing, batch), total=len(batch)))\n",
    "    passed.extend(results)\n",
    "    mask_passed = dict([(i['link'], i['num_parsed']/(i['num_overall']+1)>0.8) for i in results])\n",
    "    links_df.loc[links_df['parsed']==False,'parsed'] = links_df.loc[links_df['parsed']==False,'link']\\\n",
    "    .apply(lambda x: mask_passed.get(x, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cae7e98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     7228\n",
       "False     169\n",
       "Name: parsed, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_df['parsed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b734122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_df.to_csv('links_to_restaurants.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0705573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b48300f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
