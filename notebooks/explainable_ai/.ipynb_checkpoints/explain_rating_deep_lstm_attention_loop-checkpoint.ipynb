{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22a98b96-ef38-4f8b-9030-e31b094e0d38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers\n",
      "  Downloading tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers\n",
      "Successfully installed tokenizers-0.13.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 18:08:44.356075: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers\n",
    "import tensorflow as tf\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, trainers, Regex\n",
    "import tokenizers\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "import gc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6315b2e-3b1e-491f-87aa-1ed1e0eada8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "def str_to_list(x):\n",
    "    try:\n",
    "        return list(ast.literal_eval(x))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def string_to_list_dataframe(df):\n",
    "    columns = df.columns.tolist()\n",
    "    columns_w_lists = []\n",
    "    for column in columns:\n",
    "        if df[column].astype(str). \\\n",
    "                apply(lambda x: x.startswith('[') and x.endswith(']')) \\\n",
    "                .astype(int).mean() > 0.8:\n",
    "            columns_w_lists.append(column)\n",
    "    for column in columns_w_lists:\n",
    "        df[column] = df[column].apply(lambda x: str_to_list(x))\n",
    "        df = df[~df[column].isna()]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f328be8-1484-48c4-8c9e-646217c0e693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_rating(ratings):\n",
    "    mean_rating = np.mean(ratings)\n",
    "    if mean_rating<3:\n",
    "        return '<3'\n",
    "    elif 4>mean_rating>=3:\n",
    "        return '3'\n",
    "    elif  mean_rating>=4:\n",
    "        return '>3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77a0caf-2bf8-49b5-8541-62d02d59aaab",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e196439f-3e57-49b4-b258-e513973254a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/user/files_for_research_Vova/processed_data.csv',\\\n",
    "                 usecols=['review_translate','entity_name',\n",
    "                                                            'dataset_name',\n",
    "                                                            'rating',\n",
    "                                                           'translated'])\n",
    "subsets = pd.read_csv('/home/user/files_for_research_Vova/train_val_test_indices.csv')\n",
    "subsets = subsets.merge(df[['dataset_name', 'translated']], left_on='index', right_index=True)\n",
    "bad_indices = pd.read_csv('/home/user/files_for_research_Vova/files_to_check.csv')\n",
    "subsets = subsets[~subsets.index.isin(bad_indices['id'].values)]\n",
    "df = df[~df.index.isin(bad_indices['id'].values)]\n",
    "df, subsets = df.reset_index().drop(columns='index'), subsets.reset_index().drop(columns='index')\n",
    "mapping = dict([(i,c) for c,i in enumerate(df['rating'].unique())])\n",
    "inverse_mapping = dict([(v,k) for k,v in mapping.items()])\n",
    "df['review_translate'] = df['review_translate'].str.lower()\n",
    "if not os.path.exists('/home/user/jupyter_notebooks/df_for_ex_ai.csv'):\n",
    "    df = df[subsets['split']=='test']\n",
    "    df = df.groupby(['dataset_name','entity_name'], as_index=False).agg({'rating' : list,\n",
    "                                                   'review_translate':list\n",
    "                                                   })\n",
    "    df = df[df['rating'].apply(len)>10]\n",
    "    df['mapped_rating'] = df['rating'].apply(map_rating)\n",
    "    df_for_ex_ai = pd.DataFrame()\n",
    "    for i in df['dataset_name'].unique():\n",
    "        num_reviews_each = 15\n",
    "        df_dataset = df[df['dataset_name']==i]\n",
    "        unique_map_rat = df_dataset['mapped_rating'].unique()\n",
    "        for c, j in enumerate(unique_map_rat):\n",
    "            samples_per_cat = num_reviews_each//(len(unique_map_rat)-c)\n",
    "            df_dataset_rat = df_dataset[df_dataset['mapped_rating']==j]\n",
    "            len_df = df_dataset_rat.shape[0]\n",
    "            to_sample = samples_per_cat\n",
    "            if len_df<samples_per_cat:\n",
    "                to_sample = len_df\n",
    "            df_for_ex_ai = df_for_ex_ai.append(df_dataset_rat.sample(to_sample))\n",
    "            num_reviews_each-=to_sample\n",
    "    \n",
    "    df_for_ex_ai.reset_index().drop(columns='index')\\\n",
    "    .to_csv('/home/user/jupyter_notebooks/df_for_ex_ai.csv', index=False)\n",
    "    \n",
    "else:\n",
    "    del df;\n",
    "    gc.collect();\n",
    "    df_for_ex_ai = pd.read_csv('/home/user/jupyter_notebooks/df_for_ex_ai.csv')\n",
    "    df_for_ex_ai = string_to_list_dataframe(df_for_ex_ai)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfb26a9-6795-41e4-913d-78c7eea4f172",
   "metadata": {},
   "source": [
    "# Load model and make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9c83905-591e-411c-b5d4-4712fdd9219d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self,  \n",
    "                 units=128, **kwargs):\n",
    "        super(Attention,self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.W1=self.add_weight(name='attention_weights_1', shape=(input_shape[-1], self.units), \n",
    "                               initializer='glorot_uniform', trainable=True)\n",
    "        \n",
    "        self.W2=self.add_weight(name='attention_weights_2', shape=(1, self.units), \n",
    "                               initializer='glorot_uniform', trainable=True) \n",
    "        \n",
    "        super(Attention, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = tf.transpose(x, perm=[0, 2, 1])\n",
    "        attention = tf.nn.softmax(tf.matmul(self.W2, tf.nn.tanh(tf.matmul(self.W1, x))))\n",
    "        weighted_context = tf.reduce_sum(x * attention, axis=-1)\n",
    "        return weighted_context, attention\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'units': self.units\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd174125-ee99-49a8-ac2f-e8eb3d756ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 18:09:19.868538: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-20 18:09:20.035038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1621] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14148 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:03:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('/home/user/files_for_research_Vova/deep_lstm_attention_w2v_huber.h5',\n",
    "                                  compile=False,\n",
    "                                  custom_objects={'Attention':Attention})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100472bb-3a45-4460-b333-44efc966bfc7",
   "metadata": {},
   "source": [
    "### remake model to give back attention scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84ed9909-abdb-4b68-add2-a76e8b52e816",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attention_model = tf.keras.models.Model(inputs=model.layers[0].input,\n",
    "                                        outputs=[[i for i in model.layers if i.name=='attention'][0].output,\n",
    "                                                 model.layers[-1].output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18937d99-a802-42dd-be5b-0d335407aa9e",
   "metadata": {},
   "source": [
    "### tokenize and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbac01db-3a37-48b4-ab3f-479a1f87135a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer, models, decoders, processors\n",
    "from tokenizers import pre_tokenizers, trainers, Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85824555-75ea-4342-8341-159eba1f6dea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### because of incorrect work of BPE decoding, we should make decoding ourselves + special logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "986478a3-c5c8-405c-85b1-8edbc9f19129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BPETokenizer:\n",
    "    def __init__(self, vocab, merges):\n",
    "        self.suffix = '</w>'\n",
    "        self.tokenizer = Tokenizer(models.BPE.from_file(vocab=vocab,\n",
    "            merges=merges, end_of_word_suffix=self.suffix))\n",
    "        self.tokenizer.pre_tokenizer = pre_tokenizers.Split(Regex(r\"[\\w'-]+|[^\\w\\s'-]+\"),'removed', True)\n",
    "        self.id_to_token = self.tokenizer.id_to_token\n",
    "        self.encode_batch = self.tokenizer.encode_batch\n",
    "        self.token_to_id = self.tokenizer.token_to_id\n",
    "        self.encode = self.tokenizer.encode\n",
    "        \n",
    "    def tokens_to_ids(self, tokens):\n",
    "        return list(map(self.token_to_id, tokens))\n",
    "    \n",
    "    def ids_to_tokens(self, ids):\n",
    "        return list(map(self.id_to_token, ids))\n",
    "        \n",
    "\n",
    "    def decode(self, tokens, return_indices=False):\n",
    "        decoded = []\n",
    "        merged_indices = []\n",
    "        i = 0\n",
    "        while i<len(tokens):\n",
    "            if tokens[i].endswith(self.suffix):\n",
    "                decoded.append(tokens[i])\n",
    "                merged_indices.append([i])\n",
    "                i+=1\n",
    "            else:\n",
    "                merged_token = ''\n",
    "                tmp_indc = []\n",
    "                while not tokens[i].endswith(self.suffix):\n",
    "                    merged_token+=tokens[i]\n",
    "                    tmp_indc.append(i)\n",
    "                    i+=1\n",
    "                merged_token+=tokens[i]\n",
    "                tmp_indc.append(i)\n",
    "                decoded.append(merged_token)\n",
    "                merged_indices.append(tmp_indc)\n",
    "                i+=1\n",
    "                \n",
    "        if return_indices:\n",
    "            return decoded, merged_indices\n",
    "        else:\n",
    "            return decoded\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53f053d0-c523-448f-8523-e1b315d9c929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = BPETokenizer(vocab='/home/user/files_for_research_Vova/tokenizer_30k.json',\n",
    "            merges='/home/user/files_for_research_Vova/merges_tokenizer.txt'\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84dafca3-afd6-4840-9029-59f0ea2fe155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded = df_for_ex_ai['review_translate'].apply(lambda x: [i.ids for i in tokenizer.encode_batch(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "814dc92d-8f5a-4559-bac0-ba18a420c5ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "padded = []\n",
    "for i in encoded.values:\n",
    "    padded.append(tf.keras.preprocessing.sequence.pad_sequences(i, maxlen=300,\n",
    "                                                 padding='post'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6db21506-e2e7-4cff-b94b-3efb943006a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d749b06-b44e-46e7-941a-c8b3ba39103b",
   "metadata": {},
   "source": [
    "# Attention based explainable AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1aaf3669-4c1d-4563-a740-8fa75edd6559",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionExplainer:\n",
    "    def __init__(self, attention_model,\n",
    "                 tokenizer, mapping):\n",
    "        self.attention_model = attention_model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.mapping = mapping\n",
    "        \n",
    "    def explain(self, sample):\n",
    "        (_, attention_scores), predicted_rating = self.attention_model.predict(sample)\n",
    "        attention_scores = attention_scores.reshape(sample.shape)\n",
    "        #get only those scores which aren't relevant to PAD tokens\n",
    "        masked_scores = []\n",
    "        for i in range(attention_scores.shape[0]):\n",
    "            masked_scores.append(attention_scores[i][sample[i]!=0])\n",
    "        #actual process\n",
    "        final_scores = []\n",
    "        final_tokens = []\n",
    "        for c,sequence in enumerate(sample):\n",
    "            #map back indices to tokens\n",
    "            sequence = [i for i in sequence if i!=0]\n",
    "            tokens = self.tokenizer.ids_to_tokens(sequence)\n",
    "            #get merges of tokens\n",
    "            decoded, merged_indices = self.tokenizer.decode(tokens, True)\n",
    "            #sum up attention scores for indices which are merged\n",
    "            if len(tokens)!=len(decoded):\n",
    "                tmp_scores = []\n",
    "                for i in merged_indices:\n",
    "                    if len(i)>1:\n",
    "                        tmp_scores.append(sum([masked_scores[c][j] for j in i]))\n",
    "                    else:\n",
    "                        tmp_scores.append(masked_scores[c][i[0]])\n",
    "            else:\n",
    "                tmp_scores = list(masked_scores[c])\n",
    "            #get rid of suffix at the end of token\n",
    "            decoded = [i.rstrip(tokenizer.suffix) for i in decoded]\n",
    "            final_scores.append(tmp_scores)\n",
    "            final_tokens.append(decoded)\n",
    "        return final_scores, final_tokens, list(map(lambda x: self.mapping.get(x),\n",
    "                                                    np.argmax(predicted_rating, axis=-1)))\n",
    "                        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91c5131a-07b7-4e6d-96b6-ee1e310e375e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attention_explainer = AttentionExplainer(attention_model, tokenizer,\n",
    "                                        mapping=inverse_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949c509d-a7c4-455b-b920-a8dc5fb74512",
   "metadata": {},
   "source": [
    "### agregate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e28f1259-ce04-4e7d-a4e1-1c627a4ccdb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.65.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "!pip install tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df509004-ad69-4956-8b89-073be9051c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from functools import partial\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba3519e7-6d74-4e50-9d05-75f78ab690d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def counter_average(dict_values, counter):\n",
    "    new_dict = {}\n",
    "    for k, v in counter.items():\n",
    "        new_dict[k] = dict_values[k]/v\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bc2764d-aaa1-4a86-860c-e44f95f09bd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dicts_addition(dicts):\n",
    "    overall_dict = {}\n",
    "    for dict_ in dicts:\n",
    "        for k,v in dict_.items():\n",
    "            score = overall_dict.get(k, 0)\n",
    "            overall_dict[k] = score+v\n",
    "    return overall_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b31b4658-7f69-46cb-a433-42e558219535",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_ngrams(tokens_scores, n_gram=2, func_agg='mean'):\n",
    "    new_tokens_scores = []\n",
    "    for token_score in tokens_scores:\n",
    "        n_gram_token_score = [token_score[i:i+n_gram] \\\n",
    "                              for i in range(len(token_score)-(n_gram-1))]\n",
    "        n_gram_token_score = [(' '.join([j[0] for j in i]), sum([j[1] for j in i]))\\\n",
    "        for i in n_gram_token_score]\n",
    "        if func_agg=='mean':\n",
    "            n_gram_token_score = [(i[0], i[1]/n_gram) for i in n_gram_token_score]\n",
    "        new_tokens_scores.append(n_gram_token_score)\n",
    "    return new_tokens_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e191509-4408-4132-bae0-fd13d6311455",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def similarity_function(phrase_i, phrase_j, diversify=2):\n",
    "    sub_phrases = [' '.join(phrase_i[i:i+diversify]) for i in range(len(phrase_i)-diversify)]\n",
    "    phrase_j = ' '.join(phrase_j)\n",
    "    for i in sub_phrases:\n",
    "        if i in phrase_j:\n",
    "            return 1.0\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a27a7ee-7fdb-45d2-a5ef-8bdca5df05c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_similar(aggregated_results, diversify=2):\n",
    "    new_results = {}\n",
    "    local_similarity_function = partial(similarity_function, diversify=diversify)\n",
    "    for k, v in tqdm(aggregated_results.items()):\n",
    "        tmp_results = {}\n",
    "        phrases = [i[0].split() for i in v]\n",
    "        scores = [i[1] for i in v]\n",
    "        not_to_use = []\n",
    "        for i in range(len(phrases)):\n",
    "            if i not in not_to_use:\n",
    "                group = [i]\n",
    "                for j in range(i+1, len(phrases)):\n",
    "                    if j not in not_to_use:\n",
    "                        if local_similarity_function(phrases[i], phrases[j]) or \\\n",
    "                        local_similarity_function(phrases[j], phrases[i]):\n",
    "                            group.append(j)\n",
    "                    \n",
    "            idx, score = max(list(zip(list(group), [scores[i] for i in group])), key=lambda x: x[1])\n",
    "            not_to_use.extend(group)\n",
    "            not_to_use.remove(idx)\n",
    "            tmp_results[' '.join(phrases[idx])] = score\n",
    "        new_results[k] = list(tmp_results.items())\n",
    "        \n",
    "                   \n",
    "    return new_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28c7c318-549b-40b7-96a5-c8c072c23257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aggregate_results(scores, tokens, ratings, \n",
    "                      n_gram=1,\n",
    "                      func_agg_n_gram='mean',\n",
    "                     func_agg_overall='mean', diversify=False, top_n=None):\n",
    "    tokens_scores = [list(zip(i,scores[c])) for c, i in enumerate(tokens)]\n",
    "    if n_gram>1:\n",
    "        tokens_scores = generate_ngrams(tokens_scores, n_gram, func_agg_n_gram)\n",
    "    aggregated_results = {}\n",
    "    for c, rating in enumerate(ratings):\n",
    "        tmp_dict = {}\n",
    "        tmp_counter = Counter()\n",
    "        for token, score in tokens_scores[c]:\n",
    "            local_score = tmp_dict.get(token, 0)\n",
    "            local_score+=score\n",
    "            tmp_dict[token] = local_score\n",
    "            tmp_counter.update([token])\n",
    "                \n",
    "        previous_dict, previous_counter = aggregated_results.get(rating, [{}, Counter()]) \n",
    "        aggregated_results[rating] = [dicts_addition([tmp_dict,previous_dict]), \\\n",
    "                                      previous_counter+tmp_counter]\n",
    "    if func_agg_overall=='mean':\n",
    "        aggregated_results = dict([(k, sorted(counter_average(v[0], v[1]).items(),\n",
    "                                   key=lambda x: x[1], reverse=True)) \\\n",
    "                                                 for k, v in aggregated_results.items()])\n",
    "    else:\n",
    "        aggregated_results = dict([(k, sorted(v[0].items(),\n",
    "                                             key=lambda x: x[1], reverse=True)) \\\n",
    "                                                 for k, v in aggregated_results.items()],\n",
    "                                  )\n",
    "        \n",
    "    if diversify and n_gram>1:\n",
    "        aggregated_results = find_similar(aggregated_results, diversify)\n",
    "            \n",
    "        \n",
    "    if top_n:\n",
    "        aggregated_results = dict([(k, v[:top_n]) for k, v in aggregated_results.items()])\n",
    "    #aggregated_results = dict([(k, [i for i in v if i[1]>0]) for k,v in aggregated_results.items()])\n",
    "    return aggregated_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35608b2-e2e9-4db5-ab08-8f84da995b85",
   "metadata": {},
   "source": [
    "# LIME based explainable AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "722611cf-d480-48fe-9b17-76a8c404286e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting lime\n",
      "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from lime) (3.6.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from lime) (1.22.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from lime) (1.6.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from lime) (4.65.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.8/dist-packages (from lime) (0.24.2)\n",
      "Collecting scikit-image>=0.12\n",
      "  Downloading scikit_image-0.20.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.12->lime) (22.0)\n",
      "Collecting imageio>=2.4.1\n",
      "  Downloading imageio-2.28.1-py3-none-any.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lazy_loader>=0.1\n",
      "  Downloading lazy_loader-0.2-py3-none-any.whl (8.6 kB)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2023.4.12-py3-none-any.whl (219 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.4/219.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scipy\n",
      "  Downloading scipy-1.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx>=2.8\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow>=9.0.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.12->lime) (9.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->lime) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->lime) (1.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->lime) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->lime) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->lime) (4.38.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->lime) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->lime) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->lime) (1.0.6)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n",
      "Building wheels for collected packages: lime\n",
      "  Building wheel for lime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283858 sha256=c998d9476353a981794725c4a7f73995b25f89d685069232033852dc4b335e2f\n",
      "  Stored in directory: /root/.cache/pip/wheels/e6/a6/20/cc1e293fcdb67ede666fed293cb895395e7ecceb4467779546\n",
      "Successfully built lime\n",
      "Installing collected packages: tifffile, scipy, PyWavelets, networkx, lazy_loader, imageio, scikit-image, lime\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.6.3\n",
      "    Uninstalling scipy-1.6.3:\n",
      "      Successfully uninstalled scipy-1.6.3\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 2.6.3\n",
      "    Uninstalling networkx-2.6.3:\n",
      "      Successfully uninstalled networkx-2.6.3\n",
      "Successfully installed PyWavelets-1.4.1 imageio-2.28.1 lazy_loader-0.2 lime-0.2.0.1 networkx-3.1 scikit-image-0.20.0 scipy-1.9.1 tifffile-2023.4.12\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install lime\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b20e6321-2620-401a-80b8-fa8e12886aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_proba(arr_text, model, tokenizer, max_len, batch_size):\n",
    "    #processing\n",
    "    encoded = [i.ids for i in tokenizer.encode_batch(arr_text)]\n",
    "    padded = tf.keras.preprocessing.sequence.pad_sequences(encoded, maxlen=max_len,\n",
    "                                                 padding='post')\n",
    "    #prediction\n",
    "    pred=model.predict(padded, batch_size=batch_size)\n",
    "   \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f994a760-102e-4381-97a0-51fcee60da45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LimeExplainer:\n",
    "    def __init__(self, model, tokenizer, mapping, max_len=300, batch_size=512):\n",
    "        self.mapping = mapping\n",
    "        self.n_classes = len(self.mapping)\n",
    "        self.predict_proba = partial(predict_proba, model=model, tokenizer=tokenizer, max_len=max_len,\n",
    "                                    batch_size=batch_size)\n",
    "        self.explainer = LimeTextExplainer(class_names=self.mapping.keys(),\n",
    "                                          bow=False, feature_selection='none',\n",
    "                                          random_state=0)\n",
    "    \n",
    "    def explain(self, text_instances):\n",
    "        all_tokens = []\n",
    "        all_scores = []\n",
    "        all_ratings = []\n",
    "        for text in text_instances:\n",
    "            #use same tokenization as in lime\n",
    "            tokens = re.findall(r'\\w+', text.lower())\n",
    "            order = dict(zip(tokens, list(range(len(tokens)))))\n",
    "            ratings = []\n",
    "            scores = []\n",
    "            explanation = self.explainer.explain_instance(text, self.predict_proba,\n",
    "                                                         top_labels= self.n_classes)\n",
    "            for k, v in self.mapping.items():\n",
    "                result = explanation.as_list(k)\n",
    "                result = sorted(result, key=lambda x: order[x[0]])\n",
    "                result = [i[1] for i in result]\n",
    "                all_scores.append(result)\n",
    "                all_tokens.append(tokens)\n",
    "                all_ratings.append(v)\n",
    "                \n",
    "        return all_scores, all_tokens, all_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "863a7cbe-bf6f-4209-8039-3edc0ec599bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lime_explainer = LimeExplainer(model, tokenizer, inverse_mapping, 300, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b526d3a9-db4b-438f-9655-10e487ad361b",
   "metadata": {},
   "source": [
    "# Actual process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0747ac67-7a34-4d31-b1d7-4e4b6c54e1b3",
   "metadata": {},
   "source": [
    "## attention explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "20788c47-b56d-4ad8-9d1c-51b252669c68",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.98it/s]\u001b[A\n",
      "  2%|▏         | 1/41 [00:01<00:47,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n",
      "  5%|▍         | 2/41 [00:01<00:24,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 47.72it/s]\n",
      "  7%|▋         | 3/41 [00:01<00:15,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 231.07it/s]\n",
      " 10%|▉         | 4/41 [00:01<00:11,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 48.14it/s]\n",
      " 12%|█▏        | 5/41 [00:01<00:09,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:00<00:00, 13.31it/s]\u001b[A\n",
      " 15%|█▍        | 6/41 [00:02<00:12,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:00<00:01,  2.21it/s]\u001b[A\n",
      " 40%|████      | 2/5 [00:01<00:02,  1.32it/s]\u001b[A\n",
      " 60%|██████    | 3/5 [00:04<00:03,  1.69s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:04<00:00,  1.08it/s]\u001b[A\n",
      " 17%|█▋        | 7/41 [00:07<01:02,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:00<00:00,  7.05it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.82it/s]\u001b[A\n",
      " 20%|█▉        | 8/41 [00:08<00:50,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:00<00:01,  2.16it/s]\u001b[A\n",
      " 40%|████      | 2/5 [00:01<00:02,  1.35it/s]\u001b[A\n",
      " 60%|██████    | 3/5 [00:02<00:01,  1.32it/s]\u001b[A\n",
      " 80%|████████  | 4/5 [00:02<00:00,  1.91it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.02it/s]\u001b[A\n",
      " 22%|██▏       | 9/41 [00:11<01:02,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:00<00:00, 36.78it/s]\u001b[A\n",
      " 24%|██▍       | 10/41 [00:11<00:44,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 112.98it/s]\n",
      " 27%|██▋       | 11/41 [00:11<00:31,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:00<00:00, 227.64it/s]\n",
      " 29%|██▉       | 12/41 [00:11<00:22,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:00<00:00, 35.23it/s]\u001b[A\n",
      " 32%|███▏      | 13/41 [00:11<00:17,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:00<00:00,  8.01it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:00<00:00, 16.21it/s]\u001b[A\n",
      " 34%|███▍      | 14/41 [00:12<00:15,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 251ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.07it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  3.30it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00,  3.73it/s]\u001b[A\n",
      " 37%|███▋      | 15/41 [00:13<00:19,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 246ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.02s/it]\u001b[A\n",
      " 39%|███▉      | 16/41 [00:16<00:38,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 256ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.39it/s]\u001b[A\n",
      " 41%|████▏     | 17/41 [00:18<00:37,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [01:13<03:39, 73.27s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [01:13<01:00, 30.39s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [01:15<00:17, 17.37s/it]\u001b[A\n",
      "100%|██████████| 4/4 [01:15<00:00, 18.91s/it]\u001b[A\n",
      " 44%|████▍     | 18/41 [01:34<09:10, 23.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 214ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.14s/it]\u001b[A\n",
      " 46%|████▋     | 19/41 [01:37<06:25, 17.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 40%|████      | 2/5 [00:00<00:00,  3.82it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.52it/s]\u001b[A\n",
      " 49%|████▉     | 20/41 [01:38<04:23, 12.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 273ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:00<00:00,  6.90it/s]\u001b[A\n",
      " 50%|█████     | 2/4 [00:00<00:00,  5.19it/s]\u001b[A\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.55it/s]\u001b[A\n",
      " 51%|█████     | 21/41 [01:39<03:01,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:09<00:36,  9.05s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:25<00:40, 13.62s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:26<00:14,  7.48s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:26<00:00,  5.27s/it]\u001b[A\n",
      " 54%|█████▎    | 22/41 [02:05<04:32, 14.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:00<00:01,  2.19it/s]\u001b[A\n",
      " 40%|████      | 2/5 [00:00<00:01,  2.90it/s]\u001b[A\n",
      " 60%|██████    | 3/5 [00:01<00:00,  2.74it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.51it/s]\u001b[A\n",
      " 56%|█████▌    | 23/41 [02:07<03:09, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:01<00:01,  1.19it/s]\u001b[A\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.40it/s]\u001b[A\n",
      " 59%|█████▊    | 24/41 [02:10<02:20,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 40%|████      | 2/5 [00:00<00:00,  3.60it/s]\u001b[A\n",
      " 60%|██████    | 3/5 [00:01<00:01,  1.99it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.33it/s]\u001b[A\n",
      " 61%|██████    | 25/41 [02:12<01:40,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:06<00:25,  6.30s/it]\u001b[A\n",
      " 40%|████      | 2/5 [01:36<02:46, 55.49s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [01:38<01:02, 31.18s/it]\u001b[A\n",
      "100%|██████████| 5/5 [01:45<00:00, 21.04s/it]\u001b[A\n",
      " 63%|██████▎   | 26/41 [03:57<09:01, 36.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.05it/s]\u001b[A\n",
      " 66%|██████▌   | 27/41 [03:58<05:57, 25.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:03<00:12,  3.12s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:03<00:04,  1.35s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.48it/s]\u001b[A\n",
      " 68%|██████▊   | 28/41 [04:02<04:06, 18.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:31<02:06, 31.69s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:58<01:27, 29.00s/it]\u001b[A\n",
      "100%|██████████| 5/5 [01:00<00:00, 12.04s/it]\u001b[A\n",
      " 71%|███████   | 29/41 [05:02<06:18, 31.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 4/4 [00:00<00:00, 37.72it/s]\u001b[A\n",
      " 73%|███████▎  | 30/41 [05:03<04:03, 22.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 4/4 [00:00<00:00, 19.56it/s]\u001b[A\n",
      " 76%|███████▌  | 31/41 [05:03<02:35, 15.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:04<00:19,  4.79s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:05<00:03,  1.60s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:06<00:00,  1.32s/it]\u001b[A\n",
      " 78%|███████▊  | 32/41 [05:10<01:57, 13.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 131ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  2.27it/s]\u001b[A\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.37it/s]\u001b[A\n",
      " 80%|████████  | 33/41 [05:11<01:15,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:00<00:00,  9.48it/s]\u001b[A\n",
      " 40%|████      | 2/5 [00:00<00:00,  4.42it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.95it/s]\u001b[A\n",
      " 83%|████████▎ | 34/41 [05:12<00:47,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:00<00:00, 25.13it/s]\u001b[A\n",
      " 85%|████████▌ | 35/41 [05:12<00:29,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 35.14it/s]\n",
      " 88%|████████▊ | 36/41 [05:12<00:17,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 281ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:00<00:00,  7.30it/s]\u001b[A\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.74it/s]\u001b[A\n",
      " 90%|█████████ | 37/41 [05:13<00:10,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:04<00:19,  4.98s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:06<00:08,  2.71s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:10<00:02,  2.53s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.46s/it]\u001b[A\n",
      " 93%|█████████▎| 38/41 [05:26<00:17,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 146ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.71it/s]\u001b[A\n",
      " 95%|█████████▌| 39/41 [05:27<00:08,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 140ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:01<00:04,  1.11s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:01<00:02,  1.50it/s]\u001b[A\n",
      " 60%|██████    | 3/5 [00:01<00:00,  2.36it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.64it/s]\u001b[A\n",
      " 98%|█████████▊| 40/41 [05:29<00:03,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:09<00:38,  9.51s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:10<00:12,  4.24s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:10<00:00,  2.03s/it]\u001b[A\n",
      "100%|██████████| 41/41 [05:40<00:00,  8.30s/it]\n"
     ]
    }
   ],
   "source": [
    "attention_based_scores = []\n",
    "for i in tqdm(padded):\n",
    "    scores, tokens, ratings = attention_explainer.explain(i)\n",
    "    aggregated = aggregate_results(scores, tokens, ratings, n_gram=4, \n",
    "                  func_agg_n_gram='mean',\n",
    "                  func_agg_overall='mean',\n",
    "                  diversify=2,\n",
    "                 top_n=20)\n",
    "    attention_based_scores.append(aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d410ed2b-eee7-4a43-b4bb-52e33d803daf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5.0: [(', я задоволена !', 0.15166651271283627),\n",
       "  ('ціна на акції найвигідніша', 0.12543008709326386),\n",
       "  ('найвигідніша , можна закупити', 0.1113197198137641),\n",
       "  ('за смакоту та якість', 0.1001752377487719),\n",
       "  ('супер кашу мої діти', 0.09045768156647682),\n",
       "  ('я не дуже взявся', 0.08841430954635143),\n",
       "  ('. рекомендую кашу гербер', 0.08111168071627617),\n",
       "  ('бананом ! ну дуже', 0.07431158889085054),\n",
       "  ('не пошкодуєте ! їсть', 0.07350512407720089),\n",
       "  ('смакує . дякуємо .', 0.06995630450546741),\n",
       "  ('. малюк залишився задоволений', 0.06973411422222853),\n",
       "  ('сподобалась молочна кашка з', 0.06465916708111763),\n",
       "  ('спасибі за якість .', 0.0627228538505733),\n",
       "  ('апетитний жовтий відтінок .', 0.060781249310821295),\n",
       "  ('письмової олії . донечці', 0.05971359275281429),\n",
       "  ('! ! рекомендуємо !', 0.058080715127289295),\n",
       "  ('брати більше таких каш', 0.0574002368375659),\n",
       "  ('. моєму синочку дуже', 0.05728691373951733),\n",
       "  ('пшеничну кашу з бананом', 0.05592156224884093),\n",
       "  ('. дитині сподобалась .', 0.05554697569459677)],\n",
       " 1.0: [('дитина відмовилася їсти кашу', 0.04292064777109772)]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_based_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d7208d06-df87-4523-8e6a-29851f1d5203",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attention_explanation = pd.DataFrame(attention_based_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "51b52e0c-b86a-4465-a06a-e78df9f0b196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attention_explanation = pd.concat([df_for_ex_ai, attention_explanation], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "847048d0-3124-493e-9c18-16f0e51cdb5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attention_explanation.to_csv('/home/user/files_for_research_Vova/attention_explanation_rating.csv',\n",
    "                            index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f153d81e-a09c-4e03-be9d-deaeaa788786",
   "metadata": {},
   "source": [
    "## lime explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "631567b0-e814-4fa0-8e6c-d02120ed24f6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 24ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 24ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 3s 304ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 3s 312ms/step\n",
      "10/10 [==============================] - 0s 23ms/step\n",
      "10/10 [==============================] - 3s 312ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:00<00:02,  1.89it/s]\u001b[A\n",
      " 40%|████      | 2/5 [00:01<00:01,  1.89it/s]\u001b[A\n",
      " 60%|██████    | 3/5 [00:01<00:01,  1.93it/s]\u001b[A\n",
      " 80%|████████  | 4/5 [00:01<00:00,  2.11it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.10it/s]\u001b[A\n",
      "  2%|▏         | 1/41 [00:41<27:50, 41.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 3s 306ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 3s 310ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 3s 305ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:00<00:00, 26.88it/s]\u001b[A\n",
      "  5%|▍         | 2/41 [01:07<21:04, 32.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 3s 313ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 16ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 23ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 22ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 3s 310ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:00<00:00,  8.13it/s]\u001b[A\n",
      " 60%|██████    | 3/5 [00:00<00:00,  9.78it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:00<00:00,  9.89it/s]\u001b[A\n",
      "  7%|▋         | 3/41 [01:31<18:09, 28.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 308ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 16ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 22ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 14ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 51.87it/s]\n",
      " 10%|▉         | 4/41 [01:45<13:59, 22.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "10/10 [==============================] - 0s 16ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 23ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 14ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:00<00:00,  9.82it/s]\u001b[A\n",
      " 60%|██████    | 3/5 [00:00<00:00, 11.59it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:00<00:00, 11.71it/s]\u001b[A\n",
      " 12%|█▏        | 5/41 [02:02<12:26, 20.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 3s 307ms/step\n",
      "10/10 [==============================] - 0s 29ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "10/10 [==============================] - 3s 252ms/step\n",
      "10/10 [==============================] - 3s 312ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 16ms/step\n",
      "10/10 [==============================] - 3s 311ms/step\n",
      "10/10 [==============================] - 0s 22ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 25ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:00<00:01,  2.30it/s]\u001b[A\n",
      " 40%|████      | 2/5 [00:00<00:01,  2.24it/s]\u001b[A\n",
      " 60%|██████    | 3/5 [00:01<00:00,  2.26it/s]\u001b[A\n",
      " 80%|████████  | 4/5 [00:01<00:00,  2.25it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.29it/s]\u001b[A\n",
      " 15%|█▍        | 6/41 [02:35<14:32, 24.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 258ms/step\n",
      "10/10 [==============================] - 0s 40ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 3s 249ms/step\n",
      "10/10 [==============================] - 0s 24ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 25ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 28ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 14ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 24ms/step\n",
      "10/10 [==============================] - 0s 24ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 24ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 26ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 23ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 22ms/step\n",
      "10/10 [==============================] - 0s 36ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 26ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 27ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 16ms/step\n",
      "10/10 [==============================] - 0s 28ms/step\n",
      "10/10 [==============================] - 3s 254ms/step\n",
      "10/10 [==============================] - 0s 22ms/step\n",
      "10/10 [==============================] - 0s 16ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 28ms/step\n",
      "10/10 [==============================] - 0s 23ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 34ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 28ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:37<02:30, 37.69s/it]\u001b[A\n",
      " 40%|████      | 2/5 [01:17<01:56, 38.75s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [01:54<01:16, 38.31s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [02:35<00:38, 39.00s/it]\u001b[A\n",
      "100%|██████████| 5/5 [03:13<00:00, 38.60s/it]\u001b[A\n",
      " 17%|█▋        | 7/41 [06:54<57:29, 101.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 22ms/step\n",
      "10/10 [==============================] - 0s 35ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 28ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 24ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 23ms/step\n",
      "10/10 [==============================] - 0s 13ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 14ms/step\n",
      "10/10 [==============================] - 0s 22ms/step\n",
      "10/10 [==============================] - 0s 22ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 28ms/step\n",
      "10/10 [==============================] - 0s 24ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 26ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 14ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 22ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 14ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:02<00:10,  2.67s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:05<00:07,  2.64s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:07<00:05,  2.56s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:10<00:02,  2.60s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.63s/it]\u001b[A\n",
      " 20%|█▉        | 8/41 [07:39<45:50, 83.36s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 3s 307ms/step\n",
      "10/10 [==============================] - 3s 305ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 3s 306ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 16ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 3s 308ms/step\n",
      "10/10 [==============================] - 0s 22ms/step\n",
      "10/10 [==============================] - 0s 23ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 16ms/step\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 16ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 27ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 16ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 23ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 22ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 22ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 3s 252ms/step\n",
      "10/10 [==============================] - 0s 25ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 16ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 27ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 3s 253ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 22ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 23ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 23ms/step\n",
      "10/10 [==============================] - 0s 22ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 22ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 22ms/step\n",
      "10/10 [==============================] - 3s 306ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 40ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 3s 305ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 16ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 3s 309ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:17<01:10, 17.69s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:37<00:57, 19.03s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:56<00:38, 19.10s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [01:16<00:19, 19.14s/it]\u001b[A\n",
      "100%|██████████| 5/5 [01:35<00:00, 19.02s/it]\u001b[A\n",
      " 22%|██▏       | 9/41 [11:30<1:09:03, 129.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 25ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 3s 252ms/step\n",
      "10/10 [==============================] - 0s 22ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 22ms/step\n",
      "10/10 [==============================] - 0s 26ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 3s 305ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 23ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 9/41 [11:54<42:21, 79.42s/it]   \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m lime_based_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(df_for_ex_ai[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview_translate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m----> 3\u001b[0m     scores, tokens, ratings \u001b[38;5;241m=\u001b[39m \u001b[43mlime_explainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     aggregated \u001b[38;5;241m=\u001b[39m aggregate_results(scores, tokens, ratings, n_gram\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, \n\u001b[1;32m      5\u001b[0m                   func_agg_n_gram\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m                   func_agg_overall\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m                   diversify\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      8\u001b[0m                  top_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[1;32m      9\u001b[0m     lime_based_scores\u001b[38;5;241m.\u001b[39mappend(aggregated)\n",
      "Cell \u001b[0;32mIn[32], line 21\u001b[0m, in \u001b[0;36mLimeExplainer.explain\u001b[0;34m(self, text_instances)\u001b[0m\n\u001b[1;32m     19\u001b[0m ratings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     20\u001b[0m scores \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 21\u001b[0m explanation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mtop_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapping\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     24\u001b[0m     result \u001b[38;5;241m=\u001b[39m explanation\u001b[38;5;241m.\u001b[39mas_list(k)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/lime/lime_text.py:413\u001b[0m, in \u001b[0;36mLimeTextExplainer.explain_instance\u001b[0;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[1;32m    406\u001b[0m indexed_string \u001b[38;5;241m=\u001b[39m (IndexedCharacters(\n\u001b[1;32m    407\u001b[0m     text_instance, bow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbow, mask_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_string)\n\u001b[1;32m    408\u001b[0m                   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchar_level \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m    409\u001b[0m                   IndexedString(text_instance, bow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbow,\n\u001b[1;32m    410\u001b[0m                                 split_expression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_expression,\n\u001b[1;32m    411\u001b[0m                                 mask_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_string))\n\u001b[1;32m    412\u001b[0m domain_mapper \u001b[38;5;241m=\u001b[39m TextDomainMapper(indexed_string)\n\u001b[0;32m--> 413\u001b[0m data, yss, distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__data_labels_distances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexed_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistance_metric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(yss[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/lime/lime_text.py:472\u001b[0m, in \u001b[0;36mLimeTextExplainer.__data_labels_distances\u001b[0;34m(self, indexed_string, classifier_fn, num_samples, distance_metric)\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mpairwise\u001b[38;5;241m.\u001b[39mpairwise_distances(\n\u001b[1;32m    469\u001b[0m         x, x[\u001b[38;5;241m0\u001b[39m], metric\u001b[38;5;241m=\u001b[39mdistance_metric)\u001b[38;5;241m.\u001b[39mravel() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m    471\u001b[0m doc_size \u001b[38;5;241m=\u001b[39m indexed_string\u001b[38;5;241m.\u001b[39mnum_words()\n\u001b[0;32m--> 472\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((num_samples, doc_size))\n\u001b[1;32m    474\u001b[0m data[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(doc_size)\n",
      "File \u001b[0;32mmtrand.pyx:748\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_bounded_integers.pyx:1247\u001b[0m, in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "lime_based_scores = []\n",
    "for i in tqdm(df_for_ex_ai['review_translate'].values):\n",
    "    scores, tokens, ratings = lime_explainer.explain(i)\n",
    "    aggregated = aggregate_results(scores, tokens, ratings, n_gram=4, \n",
    "                  func_agg_n_gram='mean',\n",
    "                  func_agg_overall='mean',\n",
    "                  diversify=2,\n",
    "                 top_n=15)\n",
    "    lime_based_scores.append(aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7c66e5cf-5b89-4fcf-b824-b7da3cbf1cff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5.0: [('кашу з бананом та', 0.0858013374893315),\n",
       "  ('супер кашу мої діти', 0.05658384715989702),\n",
       "  ('смачні але й корисні', 0.05459257167274212),\n",
       "  ('та пальмової олії уже', 0.05258964286032788),\n",
       "  ('смачна кашка дитині сподобалась', 0.047062752056632254),\n",
       "  ('дуже полюбляємо кашки gerber', 0.04453189699734597),\n",
       "  ('без грудочок консистенція однорідна', 0.041658143521435154),\n",
       "  ('та манго дякуємо gerber', 0.0373434799837621),\n",
       "  ('апетитний жовтий відтінок малюк', 0.035823645026523875),\n",
       "  ('дуже хороша дитина їсть', 0.031627410718368595),\n",
       "  ('вперше дуже смачна гарно', 0.031020708189140142),\n",
       "  ('дитині цукру нам 10', 0.026260496123876736),\n",
       "  ('відмінним терміном зберігання смак', 0.02588741138647022),\n",
       "  ('дуже смачний дитині подобалося', 0.025488855405057718),\n",
       "  ('улюблена малюку дуже подобається', 0.025044478915178116)],\n",
       " 4.0: [('спробували новинку вівсяно пшеничну', 0.04774826253907043),\n",
       "  ('gerber вони не лише', 0.031869845327047126),\n",
       "  ('корисні та якісні адже', 0.030542961448246954),\n",
       "  ('пальмової олії уже спробували', 0.025218688977329838),\n",
       "  ('від гербер смак молочної', 0.02209950448231344),\n",
       "  ('і одразу дегустуємо каша', 0.021168767176657857),\n",
       "  ('я не дуже взявся', 0.019331640448612544),\n",
       "  ('адже у їхньому складі', 0.01710883533025019),\n",
       "  ('і бананом каша добре', 0.014810467567208397),\n",
       "  ('почали пробувати кашку від', 0.013380418978912147),\n",
       "  ('дитина і звичайна їжа', 0.009862310043516738),\n",
       "  ('це величезний плюс так', 0.00966463541697906),\n",
       "  ('сподобалося з манго і', 0.0085092391209348),\n",
       "  ('каша сподобалася а взагалі', 0.0074794560105506235),\n",
       "  ('снеки тепер ми почали', 0.007157483763266267)],\n",
       " 1.0: [('дитина відмовилася їсти кашу', 0.20874103965030288),\n",
       "  ('манго та бананом ну', 0.0036336291396961524),\n",
       "  ('олії це величезний плюс', 0.0034497485892390116),\n",
       "  ('і одразу дегустуємо каша', 0.0033924425860846607),\n",
       "  ('з бананом склад без', 0.003369588024704653),\n",
       "  ('якісні адже у їхньому', 0.0030636256643530157),\n",
       "  ('пару без грудочок в', 0.002486712816890233),\n",
       "  ('їхньому складі немає цукру', 0.002067602853794961),\n",
       "  ('завжди є кашки gerber', 0.00202304443726969),\n",
       "  ('нам кашка з манго', 0.00200055628400855),\n",
       "  ('склад і перевірений бренд', 0.001948677041254856),\n",
       "  ('дитина і звичайна їжа', 0.0016376760991629314),\n",
       "  ('смак каші ідеальний ніякої', 0.0014963632166326885),\n",
       "  ('і це найкраща каша', 0.0011228570314496106),\n",
       "  ('теж таку попросила і', 0.0010354461809138386)],\n",
       " 2.0: [('дитина відмовилася їсти кашу', 0.006480129953824132),\n",
       "  ('адже у їхньому складі', 0.005966804711707773),\n",
       "  ('завжди є кашки gerber', 0.0045052037314563),\n",
       "  ('і одразу дегустуємо каша', 0.004328124904464924),\n",
       "  ('олії це величезний плюс', 0.003472166882467112),\n",
       "  ('спробували новинку вівсяно пшеничну', 0.0021936666942232804),\n",
       "  ('корисні та якісні адже', 0.0016884320252338522),\n",
       "  ('пару без грудочок в', 0.0016818306933046663),\n",
       "  ('дитина і звичайна їжа', 0.0016085899837108611),\n",
       "  ('складі немає цукру та', 0.0015439624484964603),\n",
       "  ('манго та бананом ну', 0.0014158847747339745),\n",
       "  ('смак каші ідеальний ніякої', 0.0012313522164773584),\n",
       "  ('нам кашка з манго', 0.0012129197327230457),\n",
       "  ('трирічна теж таку попросила', 0.0011913238221690097),\n",
       "  ('з бананом склад без', 0.001056396173393466)],\n",
       " 3.0: [('адже у їхньому складі', 0.012868257820559356),\n",
       "  ('спробували новинку вівсяно пшеничну', 0.011449072095633058),\n",
       "  ('завжди є кашки gerber', 0.009961548277137857),\n",
       "  ('корисні та якісні адже', 0.006654653475870783),\n",
       "  ('і одразу дегустуємо каша', 0.005523143879992615),\n",
       "  ('це величезний плюс так', 0.004713428316628474),\n",
       "  ('від гербер смак молочної', 0.0037937732688343006),\n",
       "  ('gerber вони не лише', 0.003575893078870171),\n",
       "  ('дитина і звичайна їжа', 0.0029406775432815925),\n",
       "  ('розводиться без грудочок а', 0.0020963905305654523),\n",
       "  ('nestle за різноманітність вибору', 0.00198092067002618),\n",
       "  ('і пальмової олії це', 0.0018597671428312718),\n",
       "  ('почали пробувати кашку від', 0.001756042137922055),\n",
       "  ('смак каші ідеальний ніякої', 0.001749998770435972),\n",
       "  ('кашка з манго та', 0.00163396375934757)]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lime_based_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "074decf7-103d-4ec5-905e-7740916cc339",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lime_explanation = pd.DataFrame(lime_based_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "64598234-57f9-472b-9323-aff8aea60c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lime_explanation = pd.concat([df_for_ex_ai, lime_explanation], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "75f06dc8-687b-4938-a039-c7bebb3c430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_explanation.to_csv('/home/user/files_for_research_Vova/lime_explanation_rating.csv',\n",
    "                       index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fa26ac-fd66-4d7e-9398-19e74a18009b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cuda12",
   "language": "python",
   "name": "tensorflow_cuda12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
