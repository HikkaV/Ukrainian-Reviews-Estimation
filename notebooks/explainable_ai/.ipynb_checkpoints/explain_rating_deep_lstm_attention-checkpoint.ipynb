{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22a98b96-ef38-4f8b-9030-e31b094e0d38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers\n",
      "  Downloading tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers\n",
      "Successfully installed tokenizers-0.13.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 11:32:45.121417: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers\n",
    "import tensorflow as tf\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, trainers, Regex\n",
    "import tokenizers\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "import gc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6315b2e-3b1e-491f-87aa-1ed1e0eada8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "def str_to_list(x):\n",
    "    try:\n",
    "        return list(ast.literal_eval(x))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def string_to_list_dataframe(df):\n",
    "    columns = df.columns.tolist()\n",
    "    columns_w_lists = []\n",
    "    for column in columns:\n",
    "        if df[column].astype(str). \\\n",
    "                apply(lambda x: x.startswith('[') and x.endswith(']')) \\\n",
    "                .astype(int).mean() > 0.8:\n",
    "            columns_w_lists.append(column)\n",
    "    for column in columns_w_lists:\n",
    "        df[column] = df[column].apply(lambda x: str_to_list(x))\n",
    "        df = df[~df[column].isna()]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f328be8-1484-48c4-8c9e-646217c0e693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_rating(ratings):\n",
    "    mean_rating = np.mean(ratings)\n",
    "    if mean_rating<3:\n",
    "        return '<3'\n",
    "    elif 4>mean_rating>=3:\n",
    "        return '3'\n",
    "    elif  mean_rating>=4:\n",
    "        return '>3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77a0caf-2bf8-49b5-8541-62d02d59aaab",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e196439f-3e57-49b4-b258-e513973254a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/user/files_for_research_Vova/processed_data.csv',\\\n",
    "                 usecols=['review_translate','entity_name',\n",
    "                                                            'dataset_name',\n",
    "                                                            'rating',\n",
    "                                                           'translated'])\n",
    "subsets = pd.read_csv('/home/user/files_for_research_Vova/train_val_test_indices.csv')\n",
    "subsets = subsets.merge(df[['dataset_name', 'translated']], left_on='index', right_index=True)\n",
    "bad_indices = pd.read_csv('/home/user/files_for_research_Vova/files_to_check.csv')\n",
    "subsets = subsets[~subsets.index.isin(bad_indices['id'].values)]\n",
    "df = df[~df.index.isin(bad_indices['id'].values)]\n",
    "df, subsets = df.reset_index().drop(columns='index'), subsets.reset_index().drop(columns='index')\n",
    "mapping = dict([(i,c) for c,i in enumerate(df['rating'].unique())])\n",
    "inverse_mapping = dict([(v,k) for k,v in mapping.items()])\n",
    "df['review_translate'] = df['review_translate'].str.lower()\n",
    "if not os.path.exists('/home/user/jupyter_notebooks/df_for_ex_ai.csv'):\n",
    "    df = df[subsets['split']=='test']\n",
    "    df = df.groupby(['dataset_name','entity_name'], as_index=False).agg({'rating' : list,\n",
    "                                                   'review_translate':list\n",
    "                                                   })\n",
    "    df = df[df['rating'].apply(len)>10]\n",
    "    df['mapped_rating'] = df['rating'].apply(map_rating)\n",
    "    df_for_ex_ai = pd.DataFrame()\n",
    "    for i in df['dataset_name'].unique():\n",
    "        num_reviews_each = 15\n",
    "        df_dataset = df[df['dataset_name']==i]\n",
    "        unique_map_rat = df_dataset['mapped_rating'].unique()\n",
    "        for c, j in enumerate(unique_map_rat):\n",
    "            samples_per_cat = num_reviews_each//(len(unique_map_rat)-c)\n",
    "            df_dataset_rat = df_dataset[df_dataset['mapped_rating']==j]\n",
    "            len_df = df_dataset_rat.shape[0]\n",
    "            to_sample = samples_per_cat\n",
    "            if len_df<samples_per_cat:\n",
    "                to_sample = len_df\n",
    "            df_for_ex_ai = df_for_ex_ai.append(df_dataset_rat.sample(to_sample))\n",
    "            num_reviews_each-=to_sample\n",
    "    \n",
    "    df_for_ex_ai.reset_index().drop(columns='index')\\\n",
    "    .to_csv('/home/user/jupyter_notebooks/df_for_ex_ai.csv', index=False)\n",
    "    \n",
    "else:\n",
    "    del df;\n",
    "    gc.collect();\n",
    "    df_for_ex_ai = pd.read_csv('/home/user/jupyter_notebooks/df_for_ex_ai.csv')\n",
    "    df_for_ex_ai = string_to_list_dataframe(df_for_ex_ai)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfb26a9-6795-41e4-913d-78c7eea4f172",
   "metadata": {},
   "source": [
    "# Load model and make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9c83905-591e-411c-b5d4-4712fdd9219d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self,  \n",
    "                 units=128, **kwargs):\n",
    "        super(Attention,self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.W1=self.add_weight(name='attention_weights_1', shape=(input_shape[-1], self.units), \n",
    "                               initializer='glorot_uniform', trainable=True)\n",
    "        \n",
    "        self.W2=self.add_weight(name='attention_weights_2', shape=(1, self.units), \n",
    "                               initializer='glorot_uniform', trainable=True) \n",
    "        \n",
    "        super(Attention, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = tf.transpose(x, perm=[0, 2, 1])\n",
    "        attention = tf.nn.softmax(tf.matmul(self.W2, tf.nn.tanh(tf.matmul(self.W1, x))))\n",
    "        weighted_context = tf.reduce_sum(x * attention, axis=-1)\n",
    "        return weighted_context, attention\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'units': self.units\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd174125-ee99-49a8-ac2f-e8eb3d756ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 11:33:12.945972: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-20 11:33:13.115328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1621] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14148 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:03:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('/home/user/files_for_research_Vova/deep_lstm_attention_w2v_huber.h5',\n",
    "                                  compile=False,\n",
    "                                  custom_objects={'Attention':Attention})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100472bb-3a45-4460-b333-44efc966bfc7",
   "metadata": {},
   "source": [
    "### remake model to give back attention scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84ed9909-abdb-4b68-add2-a76e8b52e816",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attention_model = tf.keras.models.Model(inputs=model.layers[0].input,\n",
    "                                        outputs=[[i for i in model.layers if i.name=='attention'][0].output,\n",
    "                                                 model.layers[-1].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "566f2248-7287-45e0-9af8-185a06bb6229",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7f7490f9c820>,\n",
       " <keras.layers.core.embedding.Embedding at 0x7f7490f9c700>,\n",
       " <keras.layers.regularization.spatial_dropout1d.SpatialDropout1D at 0x7f7654383970>,\n",
       " <keras.layers.rnn.lstm.LSTM at 0x7f7490f70d60>,\n",
       " <keras.layers.normalization.layer_normalization.LayerNormalization at 0x7f748ec6f970>,\n",
       " <keras.layers.rnn.lstm.LSTM at 0x7f748ec6fc10>,\n",
       " <__main__.Attention at 0x7f748ec628b0>,\n",
       " <keras.layers.core.tf_op_layer.TFOpLambda at 0x7f7654398c10>,\n",
       " <keras.layers.core.dense.Dense at 0x7f7654363a60>,\n",
       " <keras.layers.regularization.dropout.Dropout at 0x7f748ec62b50>,\n",
       " <keras.layers.core.dense.Dense at 0x7f74890ea4c0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18937d99-a802-42dd-be5b-0d335407aa9e",
   "metadata": {},
   "source": [
    "### tokenize and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbac01db-3a37-48b4-ab3f-479a1f87135a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer, models, decoders, processors\n",
    "from tokenizers import pre_tokenizers, trainers, Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85824555-75ea-4342-8341-159eba1f6dea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### because of incorrect work of BPE decoding, we should make decoding ourselves + special logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "986478a3-c5c8-405c-85b1-8edbc9f19129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BPETokenizer:\n",
    "    def __init__(self, vocab, merges):\n",
    "        self.suffix = '</w>'\n",
    "        self.tokenizer = Tokenizer(models.BPE.from_file(vocab=vocab,\n",
    "            merges=merges, end_of_word_suffix=self.suffix))\n",
    "        self.tokenizer.pre_tokenizer = pre_tokenizers.Split(Regex(r\"[\\w'-]+|[^\\w\\s'-]+\"),'removed', True)\n",
    "        self.id_to_token = self.tokenizer.id_to_token\n",
    "        self.encode_batch = self.tokenizer.encode_batch\n",
    "        self.token_to_id = self.tokenizer.token_to_id\n",
    "        self.encode = self.tokenizer.encode\n",
    "        \n",
    "    def tokens_to_ids(self, tokens):\n",
    "        return list(map(self.token_to_id, tokens))\n",
    "    \n",
    "    def ids_to_tokens(self, ids):\n",
    "        return list(map(self.id_to_token, ids))\n",
    "        \n",
    "\n",
    "    def decode(self, tokens, return_indices=False):\n",
    "        decoded = []\n",
    "        merged_indices = []\n",
    "        i = 0\n",
    "        while i<len(tokens):\n",
    "            if tokens[i].endswith(self.suffix):\n",
    "                decoded.append(tokens[i])\n",
    "                merged_indices.append([i])\n",
    "                i+=1\n",
    "            else:\n",
    "                merged_token = ''\n",
    "                tmp_indc = []\n",
    "                while not tokens[i].endswith(self.suffix):\n",
    "                    merged_token+=tokens[i]\n",
    "                    tmp_indc.append(i)\n",
    "                    i+=1\n",
    "                merged_token+=tokens[i]\n",
    "                tmp_indc.append(i)\n",
    "                decoded.append(merged_token)\n",
    "                merged_indices.append(tmp_indc)\n",
    "                i+=1\n",
    "                \n",
    "        if return_indices:\n",
    "            return decoded, merged_indices\n",
    "        else:\n",
    "            return decoded\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53f053d0-c523-448f-8523-e1b315d9c929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = BPETokenizer(vocab='/home/user/files_for_research_Vova/tokenizer_30k.json',\n",
    "            merges='/home/user/files_for_research_Vova/merges_tokenizer.txt'\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84dafca3-afd6-4840-9029-59f0ea2fe155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded = df_for_ex_ai['review_translate'].apply(lambda x: [i.ids for i in tokenizer.encode_batch(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "814dc92d-8f5a-4559-bac0-ba18a420c5ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "padded = []\n",
    "for i in encoded.values:\n",
    "    padded.append(tf.keras.preprocessing.sequence.pad_sequences(i, maxlen=300,\n",
    "                                                 padding='post'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6db21506-e2e7-4cff-b94b-3efb943006a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 300)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d749b06-b44e-46e7-941a-c8b3ba39103b",
   "metadata": {},
   "source": [
    "# Attention based explainable AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1aaf3669-4c1d-4563-a740-8fa75edd6559",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionExplainer:\n",
    "    def __init__(self, attention_model,\n",
    "                 tokenizer, mapping):\n",
    "        self.attention_model = attention_model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.mapping = mapping\n",
    "        \n",
    "    def explain(self, sample):\n",
    "        (_, attention_scores), predicted_rating = self.attention_model.predict(sample)\n",
    "        attention_scores = attention_scores.reshape(sample.shape)\n",
    "        #get only those scores which aren't relevant to PAD tokens\n",
    "        masked_scores = []\n",
    "        for i in range(attention_scores.shape[0]):\n",
    "            masked_scores.append(attention_scores[i][sample[i]!=0])\n",
    "        #actual process\n",
    "        final_scores = []\n",
    "        final_tokens = []\n",
    "        for c,sequence in enumerate(sample):\n",
    "            #map back indices to tokens\n",
    "            sequence = [i for i in sequence if i!=0]\n",
    "            tokens = self.tokenizer.ids_to_tokens(sequence)\n",
    "            #get merges of tokens\n",
    "            decoded, merged_indices = self.tokenizer.decode(tokens, True)\n",
    "            #sum up attention scores for indices which are merged\n",
    "            if len(tokens)!=len(decoded):\n",
    "                tmp_scores = []\n",
    "                for i in merged_indices:\n",
    "                    if len(i)>1:\n",
    "                        tmp_scores.append(sum([masked_scores[c][j] for j in i]))\n",
    "                    else:\n",
    "                        tmp_scores.append(masked_scores[c][i[0]])\n",
    "            else:\n",
    "                tmp_scores = list(masked_scores[c])\n",
    "            #get rid of suffix at the end of token\n",
    "            decoded = [i.rstrip(tokenizer.suffix) for i in decoded]\n",
    "            final_scores.append(tmp_scores)\n",
    "            final_tokens.append(decoded)\n",
    "        return final_scores, final_tokens, list(map(lambda x: self.mapping.get(x),\n",
    "                                                    np.argmax(predicted_rating, axis=-1)))\n",
    "                        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "91c5131a-07b7-4e6d-96b6-ee1e310e375e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attention_explainer = AttentionExplainer(attention_model, tokenizer,\n",
    "                                        mapping=inverse_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "f21162f3-d55d-47b9-9c97-29d190cd3d60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 5.0, 1: 4.0, 2: 1.0, 3: 2.0, 4: 3.0}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "096ddd52-3d9d-4b2f-a4a9-9e69f3d0ef49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 10\n",
    "sample = padded[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "7490aa2d-5946-45c3-b843-979196ec48f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    }
   ],
   "source": [
    "scores, tokens, ratings = attention_explainer.explain(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949c509d-a7c4-455b-b920-a8dc5fb74512",
   "metadata": {},
   "source": [
    "### agregate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "e28f1259-ce04-4e7d-a4e1-1c627a4ccdb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.65.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "!pip install tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "df509004-ad69-4956-8b89-073be9051c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from functools import partial\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "ba3519e7-6d74-4e50-9d05-75f78ab690d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def counter_average(dict_values, counter):\n",
    "    new_dict = {}\n",
    "    for k, v in counter.items():\n",
    "        new_dict[k] = dict_values[k]/v\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "3bc2764d-aaa1-4a86-860c-e44f95f09bd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dicts_addition(dicts):\n",
    "    overall_dict = {}\n",
    "    for dict_ in dicts:\n",
    "        for k,v in dict_.items():\n",
    "            score = overall_dict.get(k, 0)\n",
    "            overall_dict[k] = score+v\n",
    "    return overall_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "b31b4658-7f69-46cb-a433-42e558219535",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_ngrams(tokens_scores, n_gram=2, func_agg='mean'):\n",
    "    new_tokens_scores = []\n",
    "    for token_score in tokens_scores:\n",
    "        n_gram_token_score = [token_score[i:i+n_gram] \\\n",
    "                              for i in range(len(token_score)-(n_gram-1))]\n",
    "        n_gram_token_score = [(' '.join([j[0] for j in i]), sum([j[1] for j in i]))\\\n",
    "        for i in n_gram_token_score]\n",
    "        if func_agg=='mean':\n",
    "            n_gram_token_score = [(i[0], i[1]/n_gram) for i in n_gram_token_score]\n",
    "        new_tokens_scores.append(n_gram_token_score)\n",
    "    return new_tokens_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "2e191509-4408-4132-bae0-fd13d6311455",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def similarity_function(phrase_i, phrase_j, diversify=2):\n",
    "    sub_phrases = [' '.join(phrase_i[i:i+diversify]) for i in range(len(phrase_i)-diversify)]\n",
    "    phrase_j = ' '.join(phrase_j)\n",
    "    for i in sub_phrases:\n",
    "        if i in phrase_j:\n",
    "            return 1.0\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "8a27a7ee-7fdb-45d2-a5ef-8bdca5df05c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_similar(aggregated_results, diversify=2):\n",
    "    new_results = {}\n",
    "    local_similarity_function = partial(similarity_function, diversify=diversify)\n",
    "    for k, v in tqdm(aggregated_results.items()):\n",
    "        tmp_results = {}\n",
    "        phrases = [i[0].split() for i in v]\n",
    "        scores = [i[1] for i in v]\n",
    "        not_to_use = []\n",
    "        for i in range(len(phrases)):\n",
    "            if i not in not_to_use:\n",
    "                group = [i]\n",
    "                for j in range(i+1, len(phrases)):\n",
    "                    if j not in not_to_use:\n",
    "                        if local_similarity_function(phrases[i], phrases[j]) or \\\n",
    "                        local_similarity_function(phrases[j], phrases[i]):\n",
    "                            group.append(j)\n",
    "                    \n",
    "            idx, score = max(list(zip(list(group), [scores[i] for i in group])), key=lambda x: x[1])\n",
    "            not_to_use.extend(group)\n",
    "            not_to_use.remove(idx)\n",
    "            tmp_results[' '.join(phrases[idx])] = score\n",
    "        new_results[k] = list(tmp_results.items())\n",
    "        \n",
    "                   \n",
    "    return new_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "28c7c318-549b-40b7-96a5-c8c072c23257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aggregate_results(scores, tokens, ratings, \n",
    "                      n_gram=1,\n",
    "                      func_agg_n_gram='mean',\n",
    "                     func_agg_overall='mean', diversify=False, top_n=None):\n",
    "    tokens_scores = [list(zip(i,scores[c])) for c, i in enumerate(tokens)]\n",
    "    if n_gram>1:\n",
    "        tokens_scores = generate_ngrams(tokens_scores, n_gram, func_agg_n_gram)\n",
    "    aggregated_results = {}\n",
    "    for c, rating in enumerate(ratings):\n",
    "        tmp_dict = {}\n",
    "        tmp_counter = Counter()\n",
    "        for token, score in tokens_scores[c]:\n",
    "            local_score = tmp_dict.get(token, 0)\n",
    "            local_score+=score\n",
    "            tmp_dict[token] = local_score\n",
    "            tmp_counter.update([token])\n",
    "                \n",
    "        previous_dict, previous_counter = aggregated_results.get(rating, [{}, Counter()]) \n",
    "        aggregated_results[rating] = [dicts_addition([tmp_dict,previous_dict]), \\\n",
    "                                      previous_counter+tmp_counter]\n",
    "    if func_agg_overall=='mean':\n",
    "        aggregated_results = dict([(k, sorted(counter_average(v[0], v[1]).items(),\n",
    "                                   key=lambda x: x[1], reverse=True)) \\\n",
    "                                                 for k, v in aggregated_results.items()])\n",
    "    else:\n",
    "        aggregated_results = dict([(k, sorted(v[0].items(),\n",
    "                                             key=lambda x: x[1], reverse=True)) \\\n",
    "                                                 for k, v in aggregated_results.items()],\n",
    "                                  )\n",
    "        \n",
    "    if diversify and n_gram>1:\n",
    "        aggregated_results = find_similar(aggregated_results, diversify)\n",
    "            \n",
    "        \n",
    "    if top_n:\n",
    "        aggregated_results = dict([(k, v[:top_n]) for k, v in aggregated_results.items()])\n",
    "    aggregated_results = dict([(k, [i for i in v if i[1]>0]) for k,v in aggregated_results.items()])\n",
    "    return aggregated_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "eec60268-d2c2-4adf-822c-29525f3d1f5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 107.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1.0: [('. дарма трата грошей !', 0.1412750780582428),\n",
       "  ('покупки , жахливий товар !', 0.11160582508891821),\n",
       "  ('рекомендую дуже - дуже погану', 0.10144252181053162),\n",
       "  ('після тижня використання подвійний клік', 0.09912422997877002),\n",
       "  ('перестали працювати через 2 години', 0.09833978340029717),\n",
       "  ('світиться роботом , але не', 0.0621990580111742),\n",
       "  ('погану мишу ( миша не', 0.05751111106947064),\n",
       "  ('! не раджу до покупки', 0.05716022760607302),\n",
       "  ('око красива я не рекомендую', 0.04121512891724706),\n",
       "  ('підключається до пк приходить оповіщення', 0.02945183701813221),\n",
       "  ('робот в даний час підключається', 0.025397132243961097),\n",
       "  ('працює pkm і світлодіод також', 0.020224723126739265),\n",
       "  ('! використання більше не працює', 0.016365925827994943),\n",
       "  ('найжахливіша мишка за всі часи', 0.011374722141772509),\n",
       "  ('знаходиться в правій частині миші', 0.010559833329170942),\n",
       "  ('не впала і не була', 0.010376614052802324),\n",
       "  ('але просто її викинув .', 0.008908699383027852),\n",
       "  ('підсвітка лупе в очі !', 0.008753546932712197),\n",
       "  ('була пошкоджена ! ! )', 0.006644324539229274),\n",
       "  (\"грі в tom clancy's rainbo\", 0.006535109702963382),\n",
       "  ('масивний юсб адаптер . підсвітка', 0.004702961537986994),\n",
       "  ('колесо мишки зажимається одночасно і', 0.003918024594895542),\n",
       "  ('і народи . при грі', 0.0034953391063027085),\n",
       "  ('права кнопка . також масивний', 0.002724498137831688),\n",
       "  ('rainbo six siege та натисканні', 0.001569404697511345)],\n",
       " 4.0: [('go та інших ігор зійде', 0.07322826087474824),\n",
       "  ('миша для x - go', 0.03304466847330332)],\n",
       " 5.0: [('працює відмінно . виправдав очікування', 0.10707922279834747),\n",
       "  ('дуже задоволений своєю роботою і', 0.08362701758742333),\n",
       "  ('середня за якістю . працює', 0.052121666446328166),\n",
       "  ('єдиною неточністю є робота підсвічування', 0.04400560869835317),\n",
       "  ('миша прийшла в ідеальному стані', 0.03478334210813046),\n",
       "  ('прекрасно користуюся майже рік сказав', 0.03409896455705166),\n",
       "  ('і несправному сувої , миша', 0.029634850239381193),\n",
       "  ('і зовнішнім виглядом , зручно', 0.025267254933714865),\n",
       "  ('теж радує . недоліків виявлено', 0.023759025614708662),\n",
       "  ('місяців вона ламається , я', 0.021356304921209813),\n",
       "  ('він в захваті ! дуже', 0.021288732369430362),\n",
       "  ('стані . підсвічування досить красива', 0.020755965262651443),\n",
       "  (', все у відмінному стані', 0.016720323357731104),\n",
       "  ('руці . ціна не велика', 0.015948109887540342),\n",
       "  (\"хороша і недорога комп'ютерна миша\", 0.014135195687413216),\n",
       "  ('пишу відгук кричуща миша прекрасно', 0.012776732351630926),\n",
       "  ('красива . правда полягає в', 0.010422450490295887),\n",
       "  ('миша . незважаючи на інші', 0.010170312551781534),\n",
       "  ('у вас немає шлюбу .', 0.010043402947485448),\n",
       "  ('користуюся вже 5 місяців ,', 0.0099861322902143),\n",
       "  ('прийшла , але тільки зараз', 0.009913091640919447),\n",
       "  ('тиждень використання . дуже хороша', 0.008954487461596727),\n",
       "  ('сказав , що через 6', 0.008652631426230073),\n",
       "  ('« подвійний клік » і', 0.002925336826592684),\n",
       "  ('миша вибрав син , він', 0.0021673614624887704)]}"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_results(scores, tokens, ratings, n_gram=5, \n",
    "                  func_agg_n_gram='mean',\n",
    "                  func_agg_overall='mean',\n",
    "                  diversify=2,\n",
    "                 top_n=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35608b2-e2e9-4db5-ab08-8f84da995b85",
   "metadata": {},
   "source": [
    "# LIME based explainable AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "722611cf-d480-48fe-9b17-76a8c404286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lime\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "b20e6321-2620-401a-80b8-fa8e12886aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_proba(arr_text, model, tokenizer, max_len, batch_size):\n",
    "    #processing\n",
    "    encoded = [i.ids for i in tokenizer.encode_batch(arr_text)]\n",
    "    padded = tf.keras.preprocessing.sequence.pad_sequences(encoded, maxlen=max_len,\n",
    "                                                 padding='post')\n",
    "    #prediction\n",
    "    pred=model.predict(padded, batch_size=batch_size)\n",
    "   \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "f994a760-102e-4381-97a0-51fcee60da45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LimeExplainer:\n",
    "    def __init__(self, model, tokenizer, mapping, max_len=300, batch_size=512):\n",
    "        self.mapping = mapping\n",
    "        self.n_classes = len(self.mapping)\n",
    "        self.predict_proba = partial(predict_proba, model=model, tokenizer=tokenizer, max_len=max_len,\n",
    "                                    batch_size=batch_size)\n",
    "        self.explainer = LimeTextExplainer(class_names=self.mapping.keys(),\n",
    "                                          bow=False, feature_selection='none',\n",
    "                                          random_state=0)\n",
    "    \n",
    "    def explain(self, text_instances):\n",
    "        all_tokens = []\n",
    "        all_scores = []\n",
    "        all_ratings = []\n",
    "        for text in text_instances:\n",
    "            #use same tokenization as in lime\n",
    "            tokens = re.findall(r'\\w+', text.lower())\n",
    "            order = dict(zip(tokens, list(range(len(tokens)))))\n",
    "            ratings = []\n",
    "            scores = []\n",
    "            explanation = self.explainer.explain_instance(text, self.predict_proba,\n",
    "                                                         top_labels= self.n_classes)\n",
    "            for k, v in self.mapping.items():\n",
    "                result = explanation.as_list(k)\n",
    "                result = sorted(result, key=lambda x: order[x[0]])\n",
    "                result = [i[1] for i in result]\n",
    "                all_scores.append(result)\n",
    "                all_tokens.append(tokens)\n",
    "                all_ratings.append(v)\n",
    "                \n",
    "        return all_scores, all_tokens, all_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "0a279aaa-ec7e-4eac-8e81-ecf7e80fa408",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 5.0, 1: 4.0, 2: 1.0, 3: 2.0, 4: 3.0}"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "863a7cbe-bf6f-4209-8039-3edc0ec599bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lime_explainer = LimeExplainer(model, tokenizer, inverse_mapping, 300, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "08d1496d-a9fb-4c02-a070-0345c295faec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 19ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 3s 313ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "10/10 [==============================] - 3s 309ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "10/10 [==============================] - 0s 18ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "scores, tokens, ratings = lime_explainer.explain(df_for_ex_ai['review_translate'].values[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "9670a8a0-a0c7-44f6-ad45-6be15b7e6b20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 23.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{5.0: [('пишу відгук кричуща миша прекрасно', 0.12704345848565715),\n",
       "  ('дуже хороша і недорога комп', 0.09593545508909901),\n",
       "  ('за якістю працює відмінно виправдав', 0.07419751068744385),\n",
       "  ('миша прийшла в ідеальному стані', 0.06892321404001445),\n",
       "  ('прекрасно користуюся майже рік сказав', 0.032811421117657925),\n",
       "  ('місяців все у відмінному стані', 0.028527517573954646),\n",
       "  ('в захваті дуже задоволений своєю', 0.02828972047080882),\n",
       "  ('звіт через тиждень використання дуже', 0.02793206477811964),\n",
       "  ('єдиною неточністю є робота підсвічування', 0.025447426997004956),\n",
       "  ('x go та інших ігор', 0.016020388895027653),\n",
       "  ('миші тільки на око красива', 0.015527997593701427),\n",
       "  ('ламається я можливо у вас', 0.01133608561895925),\n",
       "  ('комп ютерна миша незважаючи на', 0.011117089877517562),\n",
       "  ('робот в даний час підключається', 0.010801685502431737),\n",
       "  ('стані підсвічування досить красива правда', 0.010534434028004067)],\n",
       " 4.0: [('миша середня за якістю працює', 0.0574331782511194),\n",
       "  ('go та інших ігор зійде', 0.054659788599114224),\n",
       "  ('правда полягає в тому що', 0.044389986632248746),\n",
       "  ('пишу відгук кричуща миша прекрасно', 0.022447643527896292),\n",
       "  ('місяців вона ламається я можливо', 0.021823230135538475),\n",
       "  ('в ідеальному стані підсвічування досить', 0.02109751823845286),\n",
       "  ('найчіткіша миша для x go', 0.015444691739215966),\n",
       "  ('що єдиною неточністю є робота', 0.010804144025035186),\n",
       "  ('правій частині миші тільки на', 0.009923758514697793),\n",
       "  ('інші відгуки про подвійний клік', 0.008107347803769371),\n",
       "  ('хороша і недорога комп ютерна', 0.007193626907869445),\n",
       "  ('прекрасно користуюся майже рік сказав', 0.0054140774731161485),\n",
       "  ('сказав що через 6 місяців', 0.004997192585388785),\n",
       "  ('робота підсвічування після виключення комп', 0.004445178538670954),\n",
       "  ('робот в даний час підключається', 0.0031704221457900966)],\n",
       " 1.0: [('її викинув дарма трата грошей', 0.1476785583481157),\n",
       "  ('перестали працювати через 2 години', 0.1391168297281959),\n",
       "  ('не світиться роботом але не', 0.13321408754092467),\n",
       "  ('після тижня використання подвійний клік', 0.10714934055162684),\n",
       "  ('погану мишу миша не впала', 0.10315586785072199),\n",
       "  ('не раджу до покупки жахливий', 0.08262233124118432),\n",
       "  ('око красива я не рекомендую', 0.044211267231262875),\n",
       "  ('2 день використання більше не', 0.04038025375556619),\n",
       "  ('найжахливіша мишка за всі часи', 0.038011212311651624),\n",
       "  ('впала і не була пошкоджена', 0.03438696957292987),\n",
       "  ('підключається до пк приходить оповіщення', 0.0321188375610603),\n",
       "  ('що через 6 місяців вона', 0.016479990118107014),\n",
       "  ('миша прийшла але тільки зараз', 0.015334094739139914),\n",
       "  ('масивний юсб адаптер підсвітка лупе', 0.012531653546273225),\n",
       "  ('на колесо мишки зажимається одночасно', 0.009909893578382473)],\n",
       " 2.0: [('після тижня використання подвійний клік', 0.09856985864275111),\n",
       "  ('що через 6 місяців вона', 0.030208919758627623),\n",
       "  ('рекомендую дуже дуже погану мишу', 0.02083586279460147),\n",
       "  ('миша прийшла але тільки зараз', 0.01933155887939418),\n",
       "  ('не впала і не була', 0.01699342684252984),\n",
       "  ('пк приходить оповіщення невстановленого пристрою', 0.016423920397687815),\n",
       "  ('роботом але не робот в', 0.01368576616709961),\n",
       "  ('вона ламається я можливо у', 0.010634120977481183),\n",
       "  ('знаходиться в правій частині миші', 0.010447473923735183),\n",
       "  ('адаптер підсвітка лупе в очі', 0.009510109054309867),\n",
       "  ('працює pkm і світлодіод також', 0.008362144546905984),\n",
       "  ('на 2 день використання більше', 0.008276518698569822),\n",
       "  ('тому що єдиною неточністю є', 0.006623651940968478),\n",
       "  ('хотів її вернути але просто', 0.0066173160705219666),\n",
       "  ('інші відгуки про подвійний клік', 0.0059672107882959395)],\n",
       " 3.0: [('go та інших ігор зійде', 0.03627018963348557),\n",
       "  ('що через 6 місяців вона', 0.03621981403807742),\n",
       "  ('вона ламається я можливо у', 0.01973284401095729),\n",
       "  ('миша прийшла але тільки зараз', 0.015706319272752175),\n",
       "  ('рекомендую дуже дуже погану мишу', 0.011989049319445309),\n",
       "  ('інші відгуки про подвійний клік', 0.010565186748958353),\n",
       "  ('правда полягає в тому що', 0.01052807003479642),\n",
       "  ('що єдиною неточністю є робота', 0.0087764753143805),\n",
       "  ('знаходиться в правій частині миші', 0.008433893135168149),\n",
       "  ('пк приходить оповіщення невстановленого пристрою', 0.0073170690894958906),\n",
       "  ('користуюся майже рік сказав що', 0.004383776968409443),\n",
       "  ('працює pkm і світлодіод також', 0.004236286164093623),\n",
       "  ('клік і несправному сувої миша', 0.0033489732690301214),\n",
       "  ('її вернути але просто її', 0.003308737149372659),\n",
       "  ('адаптер підсвітка лупе в очі', 0.0024169610058684564)]}"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_results(scores, tokens, ratings, n_gram=5, \n",
    "                  func_agg_n_gram='mean',\n",
    "                  func_agg_overall='mean',\n",
    "                  diversify=2,\n",
    "                 top_n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f06dc8-687b-4938-a039-c7bebb3c430e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cuda12",
   "language": "python",
   "name": "tensorflow_cuda12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
