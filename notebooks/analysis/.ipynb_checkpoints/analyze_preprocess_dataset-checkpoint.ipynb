{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397cddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf3eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import Pool\n",
    "from contextlib import closing\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def multiprocess_func(main_input, func, additional_inputs=None,\n",
    "                      gather_func=None, to_split=True, gather_func_args=None,\n",
    "                      chunk_size=100, n_processes=8):\n",
    "    if not gather_func_args:\n",
    "        gather_func_args = []\n",
    "    if not additional_inputs:\n",
    "        additional_inputs = []\n",
    "    if not gather_func:\n",
    "        gather_func = lambda x: [z for i in x for z in i]\n",
    "    if to_split:\n",
    "        splitted = [(main_input[i:i + chunk_size], *additional_inputs) if additional_inputs else main_input[i:i + chunk_size]\\\n",
    "                    for i in range(0, len(main_input), chunk_size)]\n",
    "    else:\n",
    "        splitted = [(i, *additional_inputs) if additional_inputs else i for i in main_input]\n",
    "    with closing(Pool(n_processes)) as p:\n",
    "        result = list(tqdm(p.imap(func, splitted),\n",
    "                           total=len(splitted)))\n",
    "    return gather_func(result, *gather_func_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f245df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../data_reviews/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ac7bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "! wc -l $path/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5435f320",
   "metadata": {},
   "source": [
    "# Merging the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff82f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(os.path.join(path, 'rozetka_ukr.csv'), encoding='windows-1251', \n",
    "           sep=';')\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83695a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['entity_name'] = df1['prod_link'].apply(lambda x: x.split('/')[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ce04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[['comment','translate', 'rating', 'entity_name']]\\\n",
    ".rename(columns={'comment':'review', 'translate':'review_translate'})\n",
    "df1['dataset_name'] = 'rozetka'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7cc2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(os.path.join(path, 'rozetka_ru.csv'), encoding='windows-1251', \n",
    "           sep=';')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0228cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[~df2['prod_link'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639c5d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['entity_name'] = df2['prod_link'].apply(lambda x: x.split('/')[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bffb88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[['comment','translate', 'rating', 'entity_name']]\\\n",
    ".rename(columns={'comment':'review', 'translate':'review_translate'})\n",
    "df2['dataset_name'] = 'rozetka'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbf590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(os.path.join(path, 'hotels_final.csv'), encoding='windows-1251', \n",
    "           sep=';')\n",
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb548a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.rename(columns={'hotel_name':'entity_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742887c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3[['review', 'translate', 'overall_rating', 'entity_name']]\\\n",
    ".rename(columns={'overall_rating' : 'rating', 'translate':'review_translate'})\n",
    "df3['dataset_name'] = 'tripadvisor_hotels_ukraine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40463177",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv(os.path.join(path, 'restaurants_review_final.csv'), encoding='windows-1251', \n",
    "           sep=';')\n",
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f6d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4.rename(columns={'name':'entity_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34bb9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4.rename(columns={'overall_rating' : 'rating'})[['review', 'title_translate', 'review_translate', 'rating',\n",
    "                                                        'entity_name']]\n",
    "df4['dataset_name'] = 'tripadvisor_restaurants_ukraine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f2261",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3, df4], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca171f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d5b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df1, df2, df3, df4;\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f3a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['rating'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a35cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_translate'] = df['title_translate'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e62ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['review'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097048fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['translated'] = df['review']!=df['review_translate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eb4edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0031fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['translated'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c220c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9349f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['rating']==2].sample(1)[['review', 'review_translate']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a19c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['entity_name'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876376a5",
   "metadata": {},
   "source": [
    "# Basic data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a05838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ddaae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5653ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1795fa4d",
   "metadata": {},
   "source": [
    "## Characters number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef7924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Max number of characters in translated review : {}'.format(df['review_translate'].apply(len).max()))\n",
    "print('Min number of characters in translated review : {}'.format(df['review_translate'].apply(len).min()))\n",
    "print('Mean number of characters in translated review : {}'.format(df['review_translate'].apply(len).mean()))\n",
    "print('Median number of characters in translated review : {}'.format(df['review_translate'].apply(len).median()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729daf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log10(df['review_translate'].apply(len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0706daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(df['review_translate'].apply(len), q=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fd6db6",
   "metadata": {},
   "source": [
    "### filter out those reviews which char len is an outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8eafbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['review_translate'].apply(len)>np.percentile(df['review_translate'].apply(len), q=0.2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6ea0a9",
   "metadata": {},
   "source": [
    "### find those reviews which have a lot less characters that real text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe26a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diff_len'] = df['review'].apply(len)-df['review_translate'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e770372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['review_translate']!='#ERROR!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1d9ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diff_len'] = df['diff_len'].apply(abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35dccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log1p(df['diff_len']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea2d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['diff_len']<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd868ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['translated']==True]['diff_len'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75876145",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['diff_len'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30625276",
   "metadata": {},
   "source": [
    "### deleting empty symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf69039",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_translate'] = df['review_translate'].str.strip()\n",
    "df = df[df['review_translate'].apply(lambda x: True if x else False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3368d73d",
   "metadata": {},
   "source": [
    "### remove \\n char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6196cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['translated'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9722f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b857850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_multy_spaces(text):\n",
    "    try:\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text\n",
    "    except Exception as ex:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d539c08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_translate'] = df['review_translate'].str.replace('\\n', '').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad228c0b-2c3d-463f-932b-6287077c44df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacing_between_chars_text(text):\n",
    "    text = list(text)\n",
    "    new_text = []\n",
    "    for idx_char in range(len(text)):\n",
    "        if not text[idx_char].isalnum() and text[idx_char]!=\"'\" and text[idx_char]!=' ':\n",
    "            new_text.append(' ')\n",
    "            new_text.append(text[idx_char])\n",
    "            new_text.append(' ')\n",
    "        else:\n",
    "            new_text.append(text[idx_char])\n",
    "\n",
    "    return ''.join(new_text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a9e24a-a1e2-4548-b5d0-b6aa3e3e4b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_translate'] = multiprocess_func(df['review_translate'].values, \n",
    "                  func=spacing_between_chars_text,\n",
    "                  gather_func=lambda x: x,\n",
    "                  to_split=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0e65c9-0b87-4b9e-b242-7639f8cfe2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_translate'] = multiprocess_func(df['review_translate'].values, \n",
    "                  func=remove_multy_spaces,\n",
    "                  gather_func=lambda x: x,\n",
    "                  to_split=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8107b06c-3403-4570-92c8-6127e4df50ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_translate'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00938eb7",
   "metadata": {},
   "source": [
    "## Sentence number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe89eb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenized = multiprocess_func(df['review_translate'].values, \n",
    "                  func=sent_tokenize,\n",
    "                  gather_func=lambda x: x,\n",
    "                  to_split=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0574d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log10([len(i) for i in sent_tokenized]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20122800",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_translate_sentences'] = sent_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73ffac2",
   "metadata": {},
   "source": [
    "# Delete those which are partially translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999d5d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12698590",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.load_model('../../../lid.176.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a15573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lang_sentences(batched_texts, model):\n",
    "    result = []\n",
    "    for texts in tqdm(batched_texts):\n",
    "        lengths = [len(i) for i in texts]\n",
    "        sentences = list(chain(*texts))\n",
    "        predicted_langs, _ = model.predict(sentences)\n",
    "        predicted_langs = list(map(lambda x: x[0].split('__')[-1], predicted_langs))\n",
    "        assert sum(lengths)==len(sentences)\n",
    "        assert len(predicted_langs)==len(sentences)\n",
    "        batched_langs = []\n",
    "        start = 0\n",
    "        end = lengths[0]\n",
    "        for i in lengths[1:]:\n",
    "            to_add = predicted_langs[start:end]\n",
    "            if not to_add:\n",
    "                break\n",
    "            batched_langs.append(to_add)\n",
    "            start = end\n",
    "            end = end+i\n",
    "            \n",
    "        if predicted_langs[start:end]:\n",
    "                batched_langs.append(predicted_langs[start:end])\n",
    "        assert [len(i) for i in batched_langs]==lengths\n",
    "        result.extend(batched_langs)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0279049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lang(batched_texts, model):\n",
    "    result = []\n",
    "    for texts in tqdm(batched_texts):\n",
    "        predicted_langs, _ = model.predict(list(texts))\n",
    "        result.extend(list(map(lambda x: x[0].split('__')[-1], predicted_langs)))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdb5f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "to_detect_lang = df.loc[df['translated']==True, 'review_translate_sentences'].values\n",
    "batches = [to_detect_lang[i:i+batch_size] for i in range(0, len(to_detect_lang), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50161d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([len(i) for i in batches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d63b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = detect_lang_sentences(batches, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc43dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "to_detect_lang = df.loc[df['translated']==True, 'review_translate'].values\n",
    "batches = [to_detect_lang[i:i+batch_size] for i in range(0, len(to_detect_lang), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78ce4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = detect_lang(batches, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feb81ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['language_translated'] = 'uk'\n",
    "df.loc[df['translated']==True, 'language_translated'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4232059",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['language_translated']=='uk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd2ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='language_translated', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb2141c",
   "metadata": {},
   "source": [
    "# Tokenize texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a1a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import regexp_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814ecdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLTK_special_chars_excluded_tokenizer(input_text):\n",
    "    overall_pattern = r\"[\\w'-]+|[^\\w\\s'-]+\"\n",
    "    return regexp_tokenize(input_text, pattern=overall_pattern, gaps=False, discard_empty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb8f97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentence_tokens(sentences):\n",
    "    tokens = []\n",
    "    for sent in sentences:\n",
    "        tokens.append(NLTK_special_chars_excluded_tokenizer(sent))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adc2ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_translate_sentences_tokens'] = multiprocess_func(df['review_translate_sentences'].values, \n",
    "                  func=tokenize_sentence_tokens,\n",
    "                  gather_func=lambda x: x,\n",
    "                  to_split=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac285e1",
   "metadata": {},
   "source": [
    "# Add spaces between chars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4862487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b00405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_func_sent(sentences, func):\n",
    "    result = []\n",
    "    for sent in sentences:\n",
    "        result.append(func(sent))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d19a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacing_between_chars_tokens(tokens):\n",
    "    tokens = list(np.hstack([spacing_between_chars(i) for i in tokens]))\n",
    "    return [i for i in tokens if i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa6441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacing_between_chars(text):\n",
    "    text = list(text)\n",
    "    new_text = []\n",
    "    for idx_char in range(len(text)):\n",
    "        if not text[idx_char].isalnum() and text[idx_char]!=\"'\":\n",
    "            new_text.append(' ')\n",
    "            new_text.append(text[idx_char])\n",
    "            new_text.append(' ')\n",
    "        else:\n",
    "            new_text.append(text[idx_char])\n",
    "\n",
    "    return ''.join(new_text).strip().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb22e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing_between_chars_sentences = partial(apply_func_sent, func=spacing_between_chars_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f31e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_translate_sentences_tokens'] = multiprocess_func(df['review_translate_sentences_tokens'].values, \n",
    "                  func=spacing_between_chars_sentences,\n",
    "                  gather_func=lambda x: x,\n",
    "                  to_split=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8570369",
   "metadata": {},
   "source": [
    "# Find pos tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d935a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1e5112",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer(lang='uk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23547cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagging(ent):\n",
    "    batch, morph = ent\n",
    "    tags_batch = []\n",
    "    for sentences in batch:\n",
    "        tags_sentences = []\n",
    "        for sentence in sentences:\n",
    "            tags_sentences.append([morph.parse(word)[0].tag._POS for word in sentence])\n",
    "        tags_batch.append(tags_sentences)\n",
    "    return tags_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704558ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_translate_sentences_pos'] = multiprocess_func(df['review_translate_sentences_tokens'].values, \n",
    "                  func=pos_tagging,\n",
    "                  gather_func=None,\n",
    "                  to_split=True,\n",
    "                  chunk_size=100,\n",
    "                  n_processes=12,\n",
    "                  additional_inputs=[morph])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddc7f4f",
   "metadata": {},
   "source": [
    "# Find lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bb1292-8106-46a6-8e2b-1ac5c3e33cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizing(ent):\n",
    "    batch, morph = ent\n",
    "    tags_batch = []\n",
    "    for sentences in batch:\n",
    "        tags_sentences = []\n",
    "        for sentence in sentences:\n",
    "            tags_sentences.append([morph.parse(word)[0].normal_form for word in sentence])\n",
    "        tags_batch.append(tags_sentences)\n",
    "    return tags_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0899d983",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_translate_sentences_lemma'] = multiprocess_func(df['review_translate_sentences_tokens'].values, \n",
    "                  func=lemmatizing,\n",
    "                  gather_func=None,\n",
    "                  to_split=True,\n",
    "                  chunk_size=100,\n",
    "                  n_processes=12,\n",
    "                  additional_inputs=[morph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bba7b74-aa55-4e7d-98b8-e5e46d425366",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1b8374",
   "metadata": {},
   "source": [
    "# Delete plain questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8713a635-a11c-4562-8235-c7a2999e7875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_question_sentences(ent):\n",
    "    sentences, tags = ent\n",
    "    is_question_vector = []\n",
    "    for i in range(len(sentences)):\n",
    "        is_question_vector.append(is_question(sentences[i], tags[i]))\n",
    "    return is_question_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced6f9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_question(words, tags):\n",
    "    tags = [tag for word, tag in list(zip(words, tags))\\\n",
    "            if not word in ['.', ',', '!', '?']]\n",
    "    \n",
    "    # Check if the last character of the sentence is a question mark\n",
    "    if words[-1] == \"?\" and len(tags)>1:\n",
    "        # Check if the sentence ends with a verb or an auxiliary verb\n",
    "        if tags[-1] in [\"VERB\", \"INFN\"] or (tags[-1] == \"GRND\" and tags[-2] in [\"VERB\", \"INFN\"]):\n",
    "            return True\n",
    "        # Check if the sentence starts with an auxiliary verb and ends with a verb\n",
    "        elif tags[0] == \"PRCL\" and tags[-1] in [\"VERB\", \"INFN\"]:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif words[-1]=='?' and len(tags)==1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800b7cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_input = list(zip(df['review_translate_sentences_tokens'].values.tolist(), \n",
    "            df['review_translate_sentences_pos'].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef508e7-3f51-4499-ad45-3cb2b3bc8f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_mask = multiprocess_func(to_input, \n",
    "                  func=is_question_sentences,\n",
    "                  gather_func=lambda x: x,\n",
    "                  to_split=False,\n",
    "                  n_processes=12,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21362db-7e9d-4fda-b401-8e8e4bd4ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_question'] = questions_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b1c73f-bf3b-415c-b688-3c51b126fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['is_question'].apply(lambda x: all(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0436dce1-f72f-490f-a3b1-4943683f8a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d212b738-af8f-4455-8f38-693a71920c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
